{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f23e16c4-3cca-4209-87be-cba5c33be2cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import panel as pn\n",
    "pn.extension('tabulator')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from panel.template import FastListTemplate\n",
    "from pathlib import Path\n",
    "from yahoo_fin.stock_info import get_data\n",
    "import datetime\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# import modules that help build tabs\n",
    "import modules.helpers as helpers\n",
    "import modules.HistoricalData as hst\n",
    "import modules.MCTab as MCTab\n",
    "import modules.intro as intro\n",
    "import modules.profile as prf\n",
    "import modules.algorithmic_functions as af\n",
    "\n",
    "\n",
    "import pandas_ta as ta\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d213aa-d28d-45bb-b680-2bf77e7dd846",
   "metadata": {},
   "source": [
    "**Compile Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254e5538-46bd-42c7-9ac5-a70f859cafda",
   "metadata": {},
   "source": [
    "* If necessary/desired, use 'build_portfolio_signal_ml_df' to pull machine learning data to create/refresht he test/train datasets\n",
    "* Load the test/train datasets\n",
    "* uncomment the below code in order to create or refresh the test/train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a756f58-f037-44fb-a795-f66137577c66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# signals_df, ml_df = af.build_portfolio_signal_ml_df('conservative',2017,12,31)\n",
    "\n",
    "# af.create_train_test(ml_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "085f9b29-f645-4f1d-b3e6-c6ac1f75afc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load X_train_full and X_test_full\n",
    "X_train_full_conservative = pd.read_csv(Path(\"./data/X_train_full_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_conservative = pd.read_csv(Path(\"./data/X_test_full_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_balanced = pd.read_csv(Path(\"./data/X_train_full_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_balanced = pd.read_csv(Path(\"./data/X_test_full_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_growth = pd.read_csv(Path(\"./data/X_train_full_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_growth = pd.read_csv(Path(\"./data/X_test_full_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_aggressive = pd.read_csv(Path(\"./data/X_train_full_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_aggressive = pd.read_csv(Path(\"./data/X_test_full_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_alternative = pd.read_csv(Path(\"./data/X_train_full_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_alternative = pd.read_csv(Path(\"./data/X_test_full_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "\n",
    "\n",
    "#load y_train and y_test\n",
    "y_train_conservative = pd.read_csv(Path(\"./data/y_train_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_conservative = pd.read_csv(Path(\"./data/y_test_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_balanced = pd.read_csv(Path(\"./data/y_train_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_balanced = pd.read_csv(Path(\"./data/y_test_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_growth = pd.read_csv(Path(\"./data/y_train_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_growth = pd.read_csv(Path(\"./data/y_test_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_aggressive = pd.read_csv(Path(\"./data/y_train_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_aggressive = pd.read_csv(Path(\"./data/y_test_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_alternative = pd.read_csv(Path(\"./data/y_train_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_alternative = pd.read_csv(Path(\"./data/y_test_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "datafiles = {'conservative': [X_train_full_conservative,\n",
    "                              X_test_full_conservative, \n",
    "                              y_train_conservative, \n",
    "                              y_test_conservative],\n",
    "            'balanced': [X_train_full_balanced,\n",
    "                              X_test_full_balanced, \n",
    "                              y_train_balanced, \n",
    "                              y_test_balanced],\n",
    "            'growth': [X_train_full_growth,\n",
    "                              X_test_full_growth, \n",
    "                              y_train_growth, \n",
    "                              y_test_growth],\n",
    "            'aggressive': [X_train_full_aggressive,\n",
    "                              X_test_full_aggressive, \n",
    "                              y_train_aggressive, \n",
    "                              y_test_aggressive],\n",
    "            'alternative': [X_train_full_alternative,\n",
    "                              X_test_full_alternative, \n",
    "                              y_train_alternative, \n",
    "                              y_test_alternative]}\n",
    "\n",
    "portfolios = ['conservative', 'balanced', 'growth', 'aggressive','alternative']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a1a557-f664-4f1a-a557-e5a92bef47cd",
   "metadata": {},
   "source": [
    "**Create Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78a810cd-902f-4f6d-bb3f-f9ddcf41ee75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize standard scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a9a38c5b-5a00-4712-a9da-e62ded975935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize bagging classifier models for training and subsequent evaluation/comparison\n",
    "model1 = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, learning_rate=1.0, algorithm='SAMME')\n",
    "model2 = AdaBoostClassifier(base_estimator=LogisticRegression(solver='lbfgs'), n_estimators=50, learning_rate=0.5, algorithm='SAMME')\n",
    "model3 = AdaBoostClassifier(base_estimator=SVC(kernel='linear'), n_estimators=200, learning_rate=0.1, algorithm='SAMME')\n",
    "model4 = AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators=50), n_estimators=100, learning_rate=1.0, algorithm='SAMME')\n",
    "model5 = AdaBoostClassifier(base_estimator=GradientBoostingClassifier(max_depth=3), n_estimators=150, learning_rate=0.2, algorithm='SAMME')\n",
    "model6 = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5), n_estimators=100, learning_rate=1.0, algorithm='SAMME')\n",
    "model7 = AdaBoostClassifier(base_estimator=LogisticRegression(solver='lbfgs'), n_estimators=50, learning_rate=0.25, algorithm='SAMME')\n",
    "model8 = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3), n_estimators=200, learning_rate=0.01, algorithm='SAMME')\n",
    "model9 = AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators=50), n_estimators=100, learning_rate=0.5, algorithm='SAMME')\n",
    "model10 = AdaBoostClassifier(base_estimator=GradientBoostingClassifier(max_depth=10), n_estimators=150, learning_rate=0.1, algorithm='SAMME')\n",
    "model11 = AdaBoostClassifier(estimator=SVC(max_iter=10000), n_estimators=150, learning_rate=0.05, algorithm='SAMME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea6639e-8e7f-4bae-b23f-bd45d61cdc73",
   "metadata": {},
   "source": [
    "**Setup model pipeline, consisting of data scaling and the model training/fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "98bda12b-ba91-4163-a6d9-59063c5aa53c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# will fit/evaluate multiple models using a series of for-loops. Models will be built using all indicators at once, just SMA inidcators, just MACD indicators, and just Bollinger Band indicators\n",
    "# create list of defined models that can be looped through for fit/evaluation\n",
    "\n",
    "models = [model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, model11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "30102b2b-052e-416b-a032-9ced4977751d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning model 1\n",
      "Beginning model 2\n",
      "Beginning model 3\n",
      "Beginning model 4\n",
      "Beginning model 5\n",
      "Beginning model 6\n",
      "Beginning model 7\n",
      "Beginning model 8\n",
      "Beginning model 9\n",
      "Beginning model 10\n",
      "Beginning model 11\n",
      "Beginning model 1\n",
      "Beginning model 2\n",
      "Beginning model 3\n",
      "Beginning model 4\n",
      "Beginning model 5\n",
      "Beginning model 6\n",
      "Beginning model 7\n",
      "Beginning model 8\n",
      "Beginning model 9\n",
      "Beginning model 10\n",
      "Beginning model 11\n",
      "Beginning model 1\n",
      "Beginning model 2\n",
      "Beginning model 3\n",
      "Beginning model 4\n",
      "Beginning model 5\n",
      "Beginning model 6\n",
      "Beginning model 7\n",
      "Beginning model 8\n",
      "Beginning model 9\n",
      "Beginning model 10\n",
      "Beginning model 11\n",
      "Beginning model 1\n",
      "Beginning model 2\n",
      "Beginning model 3\n",
      "Beginning model 4\n",
      "Beginning model 5\n",
      "Beginning model 6\n",
      "Beginning model 7\n",
      "Beginning model 8\n",
      "Beginning model 9\n",
      "Beginning model 10\n",
      "Beginning model 11\n",
      "Beginning model 1\n",
      "Beginning model 2\n",
      "Beginning model 3\n",
      "Beginning model 4\n",
      "Beginning model 5\n",
      "Beginning model 6\n",
      "Beginning model 7\n",
      "Beginning model 8\n",
      "Beginning model 9\n",
      "Beginning model 10\n",
      "Beginning model 11\n"
     ]
    }
   ],
   "source": [
    "df_full_results = pd.DataFrame()\n",
    "for portfolio in portfolios:\n",
    "    \n",
    "    X_train = datafiles[portfolio][0]\n",
    "    X_test = datafiles[portfolio][1]\n",
    "    y_train = datafiles[portfolio][2]\n",
    "    y_test = datafiles[portfolio][3]\n",
    "    i=1\n",
    "    df_results = pd.DataFrame()\n",
    "    for model in models:\n",
    "        print(f\"Beginning model {i}\")\n",
    "        pipeline = Pipeline([('scaler', scaler), ('model', model)])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        preds = pipeline.predict(X_test)\n",
    "        proba = pipeline.predict_proba(X_test)\n",
    "        roc = roc_auc_score(y_test,proba[:,1])\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        df = pd.DataFrame()\n",
    "        df.loc['f1_score',f\"model{i}\"] = f1\n",
    "        df.loc['roc_auc_score',f\"model{i}\"] = roc\n",
    "        df_results = pd.concat([df_results, df], axis=1)\n",
    "        i += 1\n",
    "    df_results['type'] = portfolio\n",
    "    df_full_results = pd.concat([df_full_results, df_results])\n",
    "    \n",
    "df_full_results.set_index('type', append=True, inplace=True)\n",
    "df_full_results = df_full_results.reorder_levels(['type', 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b60183e-9914-4148-9417-e3089428ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load X_train_reduced and X_test_reduced\n",
    "X_train_reduced_conservative = pd.read_csv(Path(\"./data/X_train_reduced_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_conservative = pd.read_csv(Path(\"./data/X_test_reduced_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_balanced = pd.read_csv(Path(\"./data/X_train_reduced_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_balanced = pd.read_csv(Path(\"./data/X_test_reduced_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_growth = pd.read_csv(Path(\"./data/X_train_reduced_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_growth = pd.read_csv(Path(\"./data/X_test_reduced_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_aggressive = pd.read_csv(Path(\"./data/X_train_reduced_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_aggressive = pd.read_csv(Path(\"./data/X_test_reduced_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_alternative = pd.read_csv(Path(\"./data/X_train_reduced_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_alternative = pd.read_csv(Path(\"./data/X_test_reduced_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "\n",
    "\n",
    "#load y_train and y_test\n",
    "y_train_conservative = pd.read_csv(Path(\"./data/y_train_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_conservative = pd.read_csv(Path(\"./data/y_test_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_balanced = pd.read_csv(Path(\"./data/y_train_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_balanced = pd.read_csv(Path(\"./data/y_test_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_growth = pd.read_csv(Path(\"./data/y_train_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_growth = pd.read_csv(Path(\"./data/y_test_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_aggressive = pd.read_csv(Path(\"./data/y_train_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_aggressive = pd.read_csv(Path(\"./data/y_test_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_alternative = pd.read_csv(Path(\"./data/y_train_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_alternative = pd.read_csv(Path(\"./data/y_test_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "datafiles = {'conservative': [X_train_reduced_conservative,\n",
    "                              X_test_reduced_conservative, \n",
    "                              y_train_conservative, \n",
    "                              y_test_conservative],\n",
    "            'balanced': [X_train_reduced_balanced,\n",
    "                              X_test_reduced_balanced, \n",
    "                              y_train_balanced, \n",
    "                              y_test_balanced],\n",
    "            'growth': [X_train_reduced_growth,\n",
    "                              X_test_reduced_growth, \n",
    "                              y_train_growth, \n",
    "                              y_test_growth],\n",
    "            'aggressive': [X_train_reduced_aggressive,\n",
    "                              X_test_reduced_aggressive, \n",
    "                              y_train_aggressive, \n",
    "                              y_test_aggressive],\n",
    "            'alternative': [X_train_reduced_alternative,\n",
    "                              X_test_reduced_alternative, \n",
    "                              y_train_alternative, \n",
    "                              y_test_alternative]}\n",
    "\n",
    "portfolios = ['conservative', 'balanced', 'growth', 'aggressive','alternative']\n",
    "\n",
    "df_reduced_results = pd.DataFrame()\n",
    "for portfolio in portfolios:\n",
    "    X_train = datafiles[portfolio][0]\n",
    "    X_test = datafiles[portfolio][1]\n",
    "    y_train = datafiles[portfolio][2]\n",
    "    y_test = datafiles[portfolio][3]\n",
    "    i=1\n",
    "    df_results = pd.DataFrame()\n",
    "    for model in models:\n",
    "        pipeline = Pipeline([('scaler', scaler), ('model', model)])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        preds = pipeline.predict(X_test)\n",
    "        proba = pipeline.predict_proba(X_test)\n",
    "        roc = roc_auc_score(y_test,proba[:,1])\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        df = pd.DataFrame()\n",
    "        df.loc['f1_score',f\"model{i}\"] = f1\n",
    "        df.loc['roc_auc_score',f\"model{i}\"] = roc\n",
    "        df_results = pd.concat([df_results, df], axis=1)\n",
    "        i += 1\n",
    "    df_results['type'] = portfolio\n",
    "    df_reduced_results = pd.concat([df_reduced_results, df_results])\n",
    "    \n",
    "df_reduced_results.set_index('type', append=True, inplace=True)\n",
    "df_reduced_results = df_reduced_results.reorder_levels(['type', 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1dd54c71-c902-46a0-90a8-266b944228b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Length of order must be same as number of levels (4), got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m df_full_results\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m, append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m df_reduced_results \u001b[38;5;241m=\u001b[39m df_reduced_results\u001b[38;5;241m.\u001b[39munstack(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m df_reduced_results \u001b[38;5;241m=\u001b[39m \u001b[43mdf_reduced_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreorder_levels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m df_full_results \u001b[38;5;241m=\u001b[39m df_full_results\u001b[38;5;241m.\u001b[39munstack(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     15\u001b[0m df_full_results \u001b[38;5;241m=\u001b[39m df_full_results\u001b[38;5;241m.\u001b[39mreorder_levels([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/proj2/lib/python3.9/site-packages/pandas/core/frame.py:7559\u001b[0m, in \u001b[0;36mDataFrame.reorder_levels\u001b[0;34m(self, order, axis)\u001b[0m\n\u001b[1;32m   7557\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   7558\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex)\n\u001b[0;32m-> 7559\u001b[0m     result\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreorder_levels\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/proj2/lib/python3.9/site-packages/pandas/core/indexes/multi.py:2408\u001b[0m, in \u001b[0;36mMultiIndex.reorder_levels\u001b[0;34m(self, order)\u001b[0m\n\u001b[1;32m   2406\u001b[0m order \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_level_number(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m order]\n\u001b[1;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(order) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels:\n\u001b[0;32m-> 2408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m   2409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of order must be same as number of levels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2410\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(order)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2411\u001b[0m     )\n\u001b[1;32m   2412\u001b[0m new_levels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m order]\n\u001b[1;32m   2413\u001b[0m new_codes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodes[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m order]\n",
      "\u001b[0;31mAssertionError\u001b[0m: Length of order must be same as number of levels (4), got 2"
     ]
    }
   ],
   "source": [
    "df_reduced_results['type'] = 'Adaboost - Reduced'\n",
    "df_full_results['type'] = 'Adaboost- Full'\n",
    "\n",
    "\n",
    "df_reduced_results.set_index('type', append=True,inplace=True)\n",
    "df_full_results.set_index('type', append=True,inplace=True)\n",
    "\n",
    "df_reduced_results = df_reduced_results.unstack(level=2)\n",
    "\n",
    "df_reduced_results = df_reduced_results.reorder_levels([1,0], axis=1)\n",
    "\n",
    "\n",
    "df_full_results = df_full_results.unstack(level=2)\n",
    "\n",
    "df_full_results = df_full_results.reorder_levels([1,0], axis=1)\n",
    "\n",
    "df_adaboost_results = pd.concat([df_reduced_results, df_full_results], axis=1)\n",
    "\n",
    "cm = sns.light_palette(\"blue\", as_cmap=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "df_adaboost_results.style.highlight_max(color='lightblue', axis = 1).set_caption(\"Metrics Comparison for All Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "11ed7489-f48f-41f7-ae00-7710b39aa287",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = df_adaboost_results['Adaboost - Reduced'][['model3']]\n",
    "\n",
    "best.reset_index(inplace=True)\n",
    "\n",
    "best.to_csv(Path(\"./model_metrics/adaboost.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56b926-d541-4ab5-b29f-5f9a70f64efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
