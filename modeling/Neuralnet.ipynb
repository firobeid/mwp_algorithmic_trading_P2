{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e5fda7-1a73-4584-8af9-1c2f34aa0926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.3.2/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"tabulator\"], function(Tabulator) {\n",
       "\twindow.Tabulator = Tabulator\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"moment\"], function(moment) {\n",
       "\twindow.moment = moment\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 4;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n",
       "    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/js/tabulator.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/gridstack/gridstack@4.2.5/dist/gridstack-h5.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.14.4/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var css_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/css/tabulator_simple.min.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/debugger.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/alerts.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/card.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/widgets.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/markdown.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/json.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/loading.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/dataframe.css\"];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      inject_raw_css(\"\\n    .bk.pn-loading.arc:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n",
       "    },    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, js_modules, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.3.2/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 4;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/gridstack/gridstack@4.2.5/dist/gridstack-h5.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.14.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/css/tabulator_simple.min.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/debugger.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/alerts.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/card.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/widgets.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/markdown.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/json.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/loading.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/dataframe.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arc:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.bk-root, .bk-root .bk:before, .bk-root .bk:after {\n",
       "  font-family: var(--jp-ui-font-size1);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 16:35:23.045233: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import panel as pn\n",
    "pn.extension('tabulator')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from panel.template import FastListTemplate\n",
    "from pathlib import Path\n",
    "#from yahoo_fin.stock_info import get_data\n",
    "import datetime\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# import modules that help build tabs\n",
    "#import modules.helpers as helpers\n",
    "#import modules.HistoricalData as hst\n",
    "#import modules.MCTab as MCTab\n",
    "#import modules.intro as intro\n",
    "#import modules.profile as prf\n",
    "#import modules.algorithmic_functions as af\n",
    "\n",
    "\n",
    "#import pandas_ta as ta\n",
    "#import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#from pandas.tseries.offsets import DateOffset\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "#import seaborn as sns\n",
    "\n",
    "#from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278db87f-540c-4d6d-bb58-cd9bc8c2f229",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd137c6-1625-4288-b3c7-67f22040bf72",
   "metadata": {},
   "source": [
    "## *Data has been preprocessed*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a02c345-5d22-41df-82aa-240e5e5550f3",
   "metadata": {},
   "source": [
    "* If necessary/desired, use 'build_portfolio_signal_ml_df' to pull machine learning data to create/refresht he test/train datasets\n",
    "* Load the test/train datasets\n",
    "* uncomment the below code in order to create or refresh the test/train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984dcb3e-8ad7-4c20-8673-4be088f9cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load X_train_full and X_test_full\n",
    "X_train_full_conservative = pd.read_csv(Path(\"./data/X_train_full_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_conservative = pd.read_csv(Path(\"./data/X_test_full_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_balanced = pd.read_csv(Path(\"./data/X_train_full_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_balanced = pd.read_csv(Path(\"./data/X_test_full_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_growth = pd.read_csv(Path(\"./data/X_train_full_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_growth = pd.read_csv(Path(\"./data/X_test_full_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_aggressive = pd.read_csv(Path(\"./data/X_train_full_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_aggressive = pd.read_csv(Path(\"./data/X_test_full_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_alternative = pd.read_csv(Path(\"./data/X_train_full_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_alternative = pd.read_csv(Path(\"./data/X_test_full_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "\n",
    "\n",
    "#load y_train and y_test\n",
    "y_train_conservative = pd.read_csv(Path(\"./data/y_train_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_conservative = pd.read_csv(Path(\"./data/y_test_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_balanced = pd.read_csv(Path(\"./data/y_train_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_balanced = pd.read_csv(Path(\"./data/y_test_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_growth = pd.read_csv(Path(\"./data/y_train_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_growth = pd.read_csv(Path(\"./data/y_test_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_aggressive = pd.read_csv(Path(\"./data/y_train_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_aggressive = pd.read_csv(Path(\"./data/y_test_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_alternative = pd.read_csv(Path(\"./data/y_train_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_alternative = pd.read_csv(Path(\"./data/y_test_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "datafiles = {'conservative': [X_train_full_conservative,\n",
    "                              X_test_full_conservative, \n",
    "                              y_train_conservative, \n",
    "                              y_test_conservative],\n",
    "            'balanced': [X_train_full_balanced,\n",
    "                              X_test_full_balanced, \n",
    "                              y_train_balanced, \n",
    "                              y_test_balanced],\n",
    "            'growth': [X_train_full_growth,\n",
    "                              X_test_full_growth, \n",
    "                              y_train_growth, \n",
    "                              y_test_growth],\n",
    "            'aggressive': [X_train_full_aggressive,\n",
    "                              X_test_full_aggressive, \n",
    "                              y_train_aggressive, \n",
    "                              y_test_aggressive],\n",
    "            'alternative': [X_train_full_alternative,\n",
    "                              X_test_full_alternative, \n",
    "                              y_train_alternative, \n",
    "                              y_test_alternative]}\n",
    "\n",
    "portfolios = ['conservative', 'balanced', 'growth', 'aggressive','alternative']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71d9ca1-ce94-49d9-9bf4-664fb2bd7cb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24651f9e-befd-48d7-a988-bc66f4247344",
   "metadata": {},
   "source": [
    "## Use best parameters from tuning notebook to train one model per portfolio class for both the full and reduced feature sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749223c0-e99f-46af-8b11-d9b80ce163e7",
   "metadata": {},
   "source": [
    "### Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55245c5-74aa-404c-b55b-66e7104b7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_conservative)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_conservative_scaled = X_scaler.transform(X_train_full_conservative)\n",
    "X_test_full_conservative_scaled = X_scaler.transform(X_test_full_conservative)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057a8d4-b6e7-46f1-a72c-a677b61e50a8",
   "metadata": {},
   "source": [
    "## *Conservative Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb703c7b-c1a6-466f-ad85-d847a9c5133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 16:35:29.461650: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 0.7235 - accuracy: 0.5000 - 123ms/epoch - 18ms/step\n",
      "Loss: 0.7234643697738647, Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = 18\n",
    "hidden_nodes_layer2 = 3\n",
    "activation_1 = 'relu'\n",
    "activation_2 = 'relu'\n",
    "lr = 0.001\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_conservative = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_conservative.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_conservative.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_conservative.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_conservative.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "deep_net_conservative_model = nn_conservative.fit(X_train_full_conservative_scaled, y_train_conservative, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Conservative Model using testing data\n",
    "model_loss, model_accuracy = nn_conservative.evaluate(X_test_full_conservative_scaled, y_test_conservative, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a163e2-8926-480e-b4b6-45cb71a91f46",
   "metadata": {},
   "source": [
    "## *Balanced Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192b72d1-119f-460e-b58b-f8b5c142b599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 0.7248 - accuracy: 0.4811 - 100ms/epoch - 14ms/step\n",
      "Loss: 0.7248082160949707, Accuracy: 0.4811320900917053\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_balanced)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_balanced_scaled = X_scaler.transform(X_train_full_balanced)\n",
    "X_test_full_balanced_scaled = X_scaler.transform(X_test_full_balanced)\n",
    "\n",
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = 14\n",
    "hidden_nodes_layer2 = 3\n",
    "activation_1 = 'relu'\n",
    "activation_2 = 'tanh'\n",
    "lr = 0.001\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_balanced = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_balanced.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_balanced.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_balanced.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_balanced.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_balanced_model = nn_balanced.fit(X_train_full_balanced_scaled, y_train_balanced, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Balanced Model using testing data\n",
    "model_loss, model_accuracy = nn_balanced.evaluate(X_test_full_balanced_scaled, y_test_balanced, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae2329-87bc-4499-98b8-3d963e35b26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19f33763-0668-431b-95c0-ca56ca94a4ec",
   "metadata": {},
   "source": [
    "## *Growth Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "429921b6-fdd3-4b92-ae10-68c041ad7662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s - loss: 1.4353 - accuracy: 0.4744 - 99ms/epoch - 8ms/step\n",
      "Loss: 1.4352911710739136, Accuracy: 0.4743935167789459\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_growth)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_growth_scaled = X_scaler.transform(X_train_full_growth)\n",
    "X_test_full_growth_scaled = X_scaler.transform(X_test_full_growth)\n",
    "\n",
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = 20\n",
    "hidden_nodes_layer2 = 3\n",
    "activation_1 = 'tanh'\n",
    "activation_2 = 'relu'\n",
    "lr = 0.01\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_growth = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_growth.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_growth.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_growth.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_growth.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_growth_model = nn_growth.fit(X_train_full_growth_scaled, y_train_growth, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Growth Model using testing data\n",
    "model_loss, model_accuracy = nn_growth.evaluate(X_test_full_growth_scaled, y_test_growth, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c17114-71e2-4289-b81f-249908d1cb4f",
   "metadata": {},
   "source": [
    "## *Aggressive Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1dc6a4b-2b7c-4c05-981f-116fd683c6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s - loss: 0.8035 - accuracy: 0.5364 - 103ms/epoch - 9ms/step\n",
      "Loss: 0.8035091757774353, Accuracy: 0.5363881587982178\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_aggressive)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_aggressive_scaled = X_scaler.transform(X_train_full_aggressive)\n",
    "X_test_full_aggressive_scaled = X_scaler.transform(X_test_full_aggressive)\n",
    "\n",
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = 28\n",
    "hidden_nodes_layer2 = 3\n",
    "activation_1 = 'relu'\n",
    "activation_2 = 'tanh'\n",
    "lr = 0.01\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_aggressive = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_aggressive.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_aggressive.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_aggressive.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_aggressive.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_aggressive_model = nn_aggressive.fit(X_train_full_aggressive_scaled, y_train_aggressive, epochs=100, verbose=0)\n",
    "\n",
    "model_loss, model_accuracy = nn_aggressive.evaluate(X_test_full_aggressive_scaled, y_test_aggressive, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84757b60-fdd1-414d-aa6b-f304caf0ac2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86119757-cb41-45b1-b564-1a99e05ea7c9",
   "metadata": {},
   "source": [
    "## Alternative Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1371932a-6738-4e65-92eb-8aa37b1efc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_alternative)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_alternative_scaled = X_scaler.transform(X_train_full_alternative)\n",
    "X_test_full_alternative_scaled = X_scaler.transform(X_test_full_alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea08b4e6-2222-4de8-afbd-9a4cdf8fd28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s - loss: 1.0249 - accuracy: 0.5040 - 105ms/epoch - 9ms/step\n",
      "Loss: 1.0248531103134155, Accuracy: 0.5040431022644043\n"
     ]
    }
   ],
   "source": [
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = 14\n",
    "hidden_nodes_layer2 = 3\n",
    "activation_1 = 'tanh'\n",
    "activation_2 = 'tanh'\n",
    "lr = 0.01\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_alternative = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_alternative.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_alternative.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_alternative.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_alternative.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_alternative_model = nn_alternative.fit(X_train_full_alternative_scaled, y_train_alternative, epochs=100, verbose=0)\n",
    "\n",
    "model_loss, model_accuracy = nn_alternative.evaluate(X_test_full_alternative_scaled, y_test_alternative, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d725da9b-31bc-436f-988a-c0d7a5aab4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conservative Model\n",
      "Loss: 0.7234643697738647, Accuracy: 0.5\n",
      "\n",
      "Balanced Model\n",
      "Loss: 0.7248082160949707, Accuracy: 0.4811320900917053\n",
      "\n",
      "Growth Model\n",
      "Loss: 1.4352911710739136, Accuracy: 0.4743935167789459\n",
      "\n",
      "Aggressive Model\n",
      "Loss: 0.8035091757774353, Accuracy: 0.5363881587982178\n",
      "\n",
      "Alternative Model\n",
      "Loss: 1.0248531103134155, Accuracy: 0.5040431022644043\n"
     ]
    }
   ],
   "source": [
    "#Conservative Portfolio\n",
    "# deep_net_conservative_model = nn_conservative.fit(X_train_full_conservative_scaled, y_train_conservative, epochs=100)\n",
    "\n",
    "# Evaluate Conservative Model using testing data\n",
    "model_loss, model_accuracy = nn_conservative.evaluate(X_test_full_conservative_scaled, y_test_conservative, verbose=0)\n",
    "\n",
    "print(f\"\\nConservative Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "#Balanced Portfolio\n",
    "# deep_net_balanced_model = nn_balanced.fit(X_train_full_balanced_scaled, y_train_balanced, epochs=100)\n",
    "\n",
    "#Evaluate Balanced Model using testing data\n",
    "model_loss, model_accuracy = nn_balanced.evaluate(X_test_full_balanced_scaled, y_test_balanced, verbose=0)\n",
    "\n",
    "print(f\"\\nBalanced Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#Growth Portfolio\n",
    "# deep_net_growth_model = nn_growth.fit(X_train_full_growth_scaled, y_train_growth, epochs=100)\n",
    "\n",
    "#Evaluate Growth Model using testing data\n",
    "model_loss, model_accuracy = nn_growth.evaluate(X_test_full_growth_scaled, y_test_growth, verbose=0)\n",
    "\n",
    "print(f\"\\nGrowth Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "#Aggressive Portfolio\n",
    "# deep_net_aggressive_model = nn_aggressive.fit(X_train_full_aggressive_scaled, y_train_aggressive, epochs=100)\n",
    "\n",
    "#Evaluate Aggressive Model using testing data\n",
    "model_loss, model_accuracy = nn_aggressive.evaluate(X_test_full_aggressive_scaled, y_test_aggressive, verbose=0)\n",
    "\n",
    "print(f\"\\nAggressive Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#Alternative Portfolio\n",
    "# deep_net_alternative_model = nn_alternative.fit(X_train_full_alternative_scaled, y_train_alternative, epochs=100)\n",
    "\n",
    "#Evaluate Alternative Model using testing data\n",
    "model_loss, model_accuracy = nn_alternative.evaluate(X_test_full_alternative_scaled, y_test_alternative, verbose=0)\n",
    "\n",
    "print(f\"\\nAlternative Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5526b79-1d35-4828-9dcd-1aee8b5f0eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 865us/step\n",
      "12/12 [==============================] - 0s 815us/step\n",
      "12/12 [==============================] - 0s 805us/step\n",
      "7/7 [==============================] - 0s 863us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "full_alternative_proba = nn_alternative.predict(X_test_full_alternative_scaled)\n",
    "full_aggressive_proba = nn_aggressive.predict(X_test_full_aggressive_scaled)\n",
    "full_growth_proba = nn_growth.predict(X_test_full_growth_scaled)\n",
    "full_balanced_proba = nn_balanced.predict(X_test_full_balanced_scaled)\n",
    "full_conservative_proba = nn_conservative.predict(X_test_full_conservative_scaled)\n",
    "\n",
    "full_alternative_preds = tf.cast(full_alternative_proba >= 0.5, tf.int32)\n",
    "full_aggressive_preds = tf.cast(full_aggressive_proba >= 0.5, tf.int32)\n",
    "full_growth_preds = tf.cast(full_growth_proba >= 0.5, tf.int32)\n",
    "full_balanced_preds = tf.cast(full_balanced_proba >= 0.5, tf.int32)\n",
    "full_conservative_preds = tf.cast(full_conservative_proba >= 0.5, tf.int32)\n",
    "\n",
    "full_preds = {'alternative': [full_alternative_proba, full_alternative_preds],\n",
    "              'aggressive': [full_aggressive_proba, full_aggressive_preds],\n",
    "              'growth': [full_growth_proba, full_growth_preds],\n",
    "              'balanced': [full_balanced_proba, full_balanced_preds],\n",
    "              'conservative': [full_conservative_proba, full_conservative_preds]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60eda786-07ad-4211-9016-dda5271dc075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_results = pd.DataFrame()\n",
    "for p in portfolios:\n",
    "    y_test = datafiles[p][3]\n",
    "    proba = full_preds[p][0]\n",
    "    preds = full_preds[p][1]\n",
    "    roc = roc_auc_score(y_test,proba)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    full_results.loc[p, 'roc'] = roc\n",
    "    full_results.loc[p, 'f1'] = f1\n",
    "full_results['type'] = 'full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81660d34-c164-4745-a8a9-b1df93018db5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc</th>\n",
       "      <th>f1</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>0.473393</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced</th>\n",
       "      <td>0.512834</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>growth</th>\n",
       "      <td>0.514452</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggressive</th>\n",
       "      <td>0.545075</td>\n",
       "      <td>0.530055</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alternative</th>\n",
       "      <td>0.519740</td>\n",
       "      <td>0.619835</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   roc        f1  type\n",
       "conservative  0.473393  0.442105  full\n",
       "balanced      0.512834  0.466019  full\n",
       "growth        0.514452  0.615385  full\n",
       "aggressive    0.545075  0.530055  full\n",
       "alternative   0.519740  0.619835  full"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1625d3-9741-459a-b8f3-503cb6711c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd248f-d75e-4a5f-be0f-5075049b98eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c91004-8425-4f41-83d5-ca723b2b0e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bf8ae-65e3-4cc4-af00-b07fa5a71b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "569b287a-37e1-4f48-8369-a7073b9e43b2",
   "metadata": {},
   "source": [
    "### Reduced Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "650b29da-6f1e-442f-9817-234e44e83004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load X_train_reduced and X_test_reduced\n",
    "X_train_reduced_conservative = pd.read_csv(Path(\"./data/X_train_reduced_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_conservative = pd.read_csv(Path(\"./data/X_test_reduced_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_balanced = pd.read_csv(Path(\"./data/X_train_reduced_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_balanced = pd.read_csv(Path(\"./data/X_test_reduced_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_growth = pd.read_csv(Path(\"./data/X_train_reduced_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_growth = pd.read_csv(Path(\"./data/X_test_reduced_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_aggressive = pd.read_csv(Path(\"./data/X_train_reduced_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_aggressive = pd.read_csv(Path(\"./data/X_test_reduced_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_alternative = pd.read_csv(Path(\"./data/X_train_reduced_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_alternative = pd.read_csv(Path(\"./data/X_test_reduced_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "\n",
    "\n",
    "#load y_train and y_test\n",
    "y_train_conservative = pd.read_csv(Path(\"./data/y_train_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_conservative = pd.read_csv(Path(\"./data/y_test_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_balanced = pd.read_csv(Path(\"./data/y_train_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_balanced = pd.read_csv(Path(\"./data/y_test_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_growth = pd.read_csv(Path(\"./data/y_train_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_growth = pd.read_csv(Path(\"./data/y_test_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_aggressive = pd.read_csv(Path(\"./data/y_train_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_aggressive = pd.read_csv(Path(\"./data/y_test_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_alternative = pd.read_csv(Path(\"./data/y_train_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_alternative = pd.read_csv(Path(\"./data/y_test_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "datafiles = {'conservative': [X_train_reduced_conservative,\n",
    "                              X_test_reduced_conservative, \n",
    "                              y_train_conservative, \n",
    "                              y_test_conservative],\n",
    "            'balanced': [X_train_reduced_balanced,\n",
    "                              X_test_reduced_balanced, \n",
    "                              y_train_balanced, \n",
    "                              y_test_balanced],\n",
    "            'growth': [X_train_reduced_growth,\n",
    "                              X_test_reduced_growth, \n",
    "                              y_train_growth, \n",
    "                              y_test_growth],\n",
    "            'aggressive': [X_train_reduced_aggressive,\n",
    "                              X_test_reduced_aggressive, \n",
    "                              y_train_aggressive, \n",
    "                              y_test_aggressive],\n",
    "            'alternative': [X_train_reduced_alternative,\n",
    "                              X_test_reduced_alternative, \n",
    "                              y_train_alternative, \n",
    "                              y_test_alternative]}\n",
    "\n",
    "portfolios = ['conservative', 'balanced', 'growth', 'aggressive','alternative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "014e1aad-b5b2-4782-9e1a-a77b0450f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_conservative)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_conservative_scaled = X_scaler.transform(X_train_reduced_conservative)\n",
    "X_test_reduced_conservative_scaled = X_scaler.transform(X_test_reduced_conservative)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2fdda6-df30-4d45-92ba-bbaca5b38df5",
   "metadata": {},
   "source": [
    "## *Conservative Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fe604bd-5953-40cd-85d5-dbc51ff13d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 0.7923 - accuracy: 0.5189 - 102ms/epoch - 15ms/step\n",
      "Loss: 0.7923059463500977, Accuracy: 0.5188679099082947\n"
     ]
    }
   ],
   "source": [
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = 18\n",
    "hidden_nodes_layer2 = 9\n",
    "activation_1 = 'tanh'\n",
    "activation_2 = 'relu'\n",
    "lr = 0.01\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_conservative = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_conservative.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_conservative.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_conservative.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_conservative.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "deep_net_conservative_model = nn_conservative.fit(X_train_reduced_conservative_scaled, y_train_conservative, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Conservative Model using testing data\n",
    "model_loss, model_accuracy = nn_conservative.evaluate(X_test_reduced_conservative_scaled, y_test_conservative, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2802a3c-f7be-48d7-ba3b-51217b9aa5c4",
   "metadata": {},
   "source": [
    "## *Balanced Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b534977d-d76f-496e-953a-cd29a6855f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 0.7013 - accuracy: 0.5094 - 101ms/epoch - 14ms/step\n",
      "Loss: 0.7012689709663391, Accuracy: 0.5094339847564697\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_balanced)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_balanced_scaled = X_scaler.transform(X_train_reduced_balanced)\n",
    "X_test_reduced_balanced_scaled = X_scaler.transform(X_test_reduced_balanced)\n",
    "\n",
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = 12\n",
    "hidden_nodes_layer2 = 7\n",
    "activation_1 = 'relu'\n",
    "activation_2 = 'relu'\n",
    "lr = 0.001\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_balanced = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_balanced.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_balanced.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_balanced.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_balanced.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_balanced_model = nn_balanced.fit(X_train_reduced_balanced_scaled, y_train_balanced, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Balanced Model using testing data\n",
    "model_loss, model_accuracy = nn_balanced.evaluate(X_test_reduced_balanced_scaled, y_test_balanced, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d6480-2919-4841-acc8-c64d37c5bc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d744e0c-4935-471f-b077-a49a109909f9",
   "metadata": {},
   "source": [
    "## *Growth Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "627eeef1-a42e-47e5-8fa0-e9959e5f9b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s - loss: 0.6864 - accuracy: 0.5418 - 106ms/epoch - 9ms/step\n",
      "Loss: 0.6863937377929688, Accuracy: 0.5417789816856384\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_growth)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_growth_scaled = X_scaler.transform(X_train_reduced_growth)\n",
    "X_test_reduced_growth_scaled = X_scaler.transform(X_test_reduced_growth)\n",
    "\n",
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = 36\n",
    "hidden_nodes_layer2 = 9\n",
    "activation_1 = 'relu'\n",
    "activation_2 = 'relu'\n",
    "lr = 0.0001\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_growth = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_growth.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_growth.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_growth.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_growth.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_growth_model = nn_growth.fit(X_train_reduced_growth_scaled, y_train_growth, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Growth Model using testing data\n",
    "model_loss, model_accuracy = nn_growth.evaluate(X_test_reduced_growth_scaled, y_test_growth, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f64ac-82e7-4c75-b012-d55977c6866a",
   "metadata": {},
   "source": [
    "## *Aggressive Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af15b3fd-1c41-4ca8-96d0-120b78b3f805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s - loss: 0.9432 - accuracy: 0.4960 - 157ms/epoch - 13ms/step\n",
      "Loss: 0.9432427883148193, Accuracy: 0.4959568679332733\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_aggressive)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_aggressive_scaled = X_scaler.transform(X_train_reduced_aggressive)\n",
    "X_test_reduced_aggressive_scaled = X_scaler.transform(X_test_reduced_aggressive)\n",
    "\n",
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = 30\n",
    "hidden_nodes_layer2 = 3\n",
    "activation_1 = 'tanh'\n",
    "activation_2 = 'relu'\n",
    "lr = 0.01\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_aggressive = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_aggressive.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_aggressive.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_aggressive.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_aggressive.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_aggressive_model = nn_aggressive.fit(X_train_reduced_aggressive_scaled, y_train_aggressive, epochs=100, verbose=0)\n",
    "\n",
    "model_loss, model_accuracy = nn_aggressive.evaluate(X_test_reduced_aggressive_scaled, y_test_aggressive, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355dc408-8d00-4f08-8ac5-755ab308d979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88ab6ec9-4596-4b0b-bbcb-6154a727cf63",
   "metadata": {},
   "source": [
    "## Alternative Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eca1f350-df35-4498-b481-80b33d08d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_alternative)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_alternative_scaled = X_scaler.transform(X_train_reduced_alternative)\n",
    "X_test_reduced_alternative_scaled = X_scaler.transform(X_test_reduced_alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe9f915a-f8f3-4039-b803-e12f964de789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s - loss: 0.6959 - accuracy: 0.4906 - 104ms/epoch - 9ms/step\n",
      "Loss: 0.6959148645401001, Accuracy: 0.49056604504585266\n"
     ]
    }
   ],
   "source": [
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = 8\n",
    "hidden_nodes_layer2 = 3\n",
    "activation_1 = 'relu'\n",
    "activation_2 = 'relu'\n",
    "lr = 0.001\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_alternative = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_alternative.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_alternative.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_alternative.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_alternative.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_alternative_model = nn_alternative.fit(X_train_reduced_alternative_scaled, y_train_alternative, epochs=100, verbose=0)\n",
    "\n",
    "model_loss, model_accuracy = nn_alternative.evaluate(X_test_reduced_alternative_scaled, y_test_alternative, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9da7bb63-6561-4c1a-9c16-d82e4dddfb63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conservative Model\n",
      "Loss: 0.7923059463500977, Accuracy: 0.5188679099082947\n",
      "\n",
      "Balanced Model\n",
      "Loss: 0.7012689709663391, Accuracy: 0.5094339847564697\n",
      "\n",
      "Growth Model\n",
      "Loss: 0.6863937377929688, Accuracy: 0.5417789816856384\n",
      "\n",
      "Aggressive Model\n",
      "Loss: 0.9432427883148193, Accuracy: 0.4959568679332733\n",
      "\n",
      "Alternative Model\n",
      "Loss: 0.6959148645401001, Accuracy: 0.49056604504585266\n"
     ]
    }
   ],
   "source": [
    "#Conservative Portfolio\n",
    "# deep_net_conservative_model = nn_conservative.fit(X_train_full_conservative_scaled, y_train_conservative, epochs=100)\n",
    "\n",
    "# Evaluate Conservative Model using testing data\n",
    "model_loss, model_accuracy = nn_conservative.evaluate(X_test_reduced_conservative_scaled, y_test_conservative, verbose=0)\n",
    "\n",
    "print(f\"\\nConservative Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "#Balanced Portfolio\n",
    "# deep_net_balanced_model = nn_balanced.fit(X_train_full_balanced_scaled, y_train_balanced, epochs=100)\n",
    "\n",
    "#Evaluate Balanced Model using testing data\n",
    "model_loss, model_accuracy = nn_balanced.evaluate(X_test_reduced_balanced_scaled, y_test_balanced, verbose=0)\n",
    "\n",
    "print(f\"\\nBalanced Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#Growth Portfolio\n",
    "# deep_net_growth_model = nn_growth.fit(X_train_full_growth_scaled, y_train_growth, epochs=100)\n",
    "\n",
    "#Evaluate Growth Model using testing data\n",
    "model_loss, model_accuracy = nn_growth.evaluate(X_test_reduced_growth_scaled, y_test_growth, verbose=0)\n",
    "\n",
    "print(f\"\\nGrowth Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "#Aggressive Portfolio\n",
    "# deep_net_aggressive_model = nn_aggressive.fit(X_train_full_aggressive_scaled, y_train_aggressive, epochs=100)\n",
    "\n",
    "#Evaluate Aggressive Model using testing data\n",
    "model_loss, model_accuracy = nn_aggressive.evaluate(X_test_reduced_aggressive_scaled, y_test_aggressive, verbose=0)\n",
    "\n",
    "print(f\"\\nAggressive Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#Alternative Portfolio\n",
    "# deep_net_alternative_model = nn_alternative.fit(X_train_full_alternative_scaled, y_train_alternative, epochs=100)\n",
    "\n",
    "#Evaluate Alternative Model using testing data\n",
    "model_loss, model_accuracy = nn_alternative.evaluate(X_test_reduced_alternative_scaled, y_test_alternative, verbose=0)\n",
    "\n",
    "print(f\"\\nAlternative Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfe4a6bb-35f9-4fa8-a4cc-d2049c4b2b14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 805us/step\n",
      "12/12 [==============================] - 0s 788us/step\n",
      "7/7 [==============================] - 0s 944us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "reduced_alternative_proba = nn_alternative.predict(X_test_reduced_alternative_scaled)\n",
    "reduced_aggressive_proba = nn_aggressive.predict(X_test_reduced_aggressive_scaled)\n",
    "reduced_growth_proba = nn_growth.predict(X_test_reduced_growth_scaled)\n",
    "reduced_balanced_proba = nn_balanced.predict(X_test_reduced_balanced_scaled)\n",
    "reduced_conservative_proba = nn_conservative.predict(X_test_reduced_conservative_scaled)\n",
    "\n",
    "reduced_alternative_preds = tf.cast(reduced_alternative_proba >= 0.5, tf.int32)\n",
    "reduced_aggressive_preds = tf.cast(reduced_aggressive_proba >= 0.5, tf.int32)\n",
    "reduced_growth_preds = tf.cast(reduced_growth_proba >= 0.5, tf.int32)\n",
    "reduced_balanced_preds = tf.cast(reduced_balanced_proba >= 0.5, tf.int32)\n",
    "reduced_conservative_preds = tf.cast(reduced_conservative_proba >= 0.5, tf.int32)\n",
    "\n",
    "reduced_preds = {'alternative': [reduced_alternative_proba, reduced_alternative_preds],\n",
    "              'aggressive': [reduced_aggressive_proba, reduced_aggressive_preds],\n",
    "              'growth': [reduced_growth_proba, reduced_growth_preds],\n",
    "              'balanced': [reduced_balanced_proba, reduced_balanced_preds],\n",
    "              'conservative': [reduced_conservative_proba, reduced_conservative_preds]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3e99f2dd-3c63-471c-8268-841f838dbb0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>reduced</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">conservative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.495446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">balanced</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.503922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">growth</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.563332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.532967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">aggressive</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.534421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.611227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">alternative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.548462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             reduced\n",
       "type                                \n",
       "conservative roc_auc_score  0.495446\n",
       "             f1_score       0.484848\n",
       "balanced     roc_auc_score  0.503922\n",
       "             f1_score       0.500000\n",
       "growth       roc_auc_score  0.563332\n",
       "             f1_score       0.532967\n",
       "aggressive   roc_auc_score  0.534421\n",
       "             f1_score       0.611227\n",
       "alternative  roc_auc_score  0.548462\n",
       "             f1_score       0.658228"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_results = pd.DataFrame()\n",
    "for p in portfolios:\n",
    "    y_test = datafiles[p][3]\n",
    "    proba = reduced_preds[p][0]\n",
    "    preds = reduced_preds[p][1]\n",
    "    roc = roc_auc_score(y_test,proba)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    df = pd.DataFrame()\n",
    "    df.loc['roc_auc_score','reduced'] = roc\n",
    "    df.loc['f1_score', 'reduced'] = f1\n",
    "    df['type'] = p\n",
    "    reduced_results = pd.concat([reduced_results, df], axis=0)\n",
    "\n",
    "\n",
    "reduced_results.set_index('type', append=True, inplace=True)\n",
    "\n",
    "reduced_results = reduced_results.reorder_levels(['type',0])\n",
    "\n",
    "reduced_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0b480072-18d1-4364-b757-025e129d721d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>full</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">conservative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.473393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.442105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">balanced</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.512834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.466019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">growth</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.514452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">aggressive</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.545075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.530055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">alternative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.519740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.619835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                full\n",
       "type                                \n",
       "conservative roc_auc_score  0.473393\n",
       "             f1_score       0.442105\n",
       "balanced     roc_auc_score  0.512834\n",
       "             f1_score       0.466019\n",
       "growth       roc_auc_score  0.514452\n",
       "             f1_score       0.615385\n",
       "aggressive   roc_auc_score  0.545075\n",
       "             f1_score       0.530055\n",
       "alternative  roc_auc_score  0.519740\n",
       "             f1_score       0.619835"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results = pd.DataFrame()\n",
    "for p in portfolios:\n",
    "    y_test = datafiles[p][3]\n",
    "    proba = full_preds[p][0]\n",
    "    preds = full_preds[p][1]\n",
    "    roc = roc_auc_score(y_test,proba)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    df = pd.DataFrame()\n",
    "    df.loc['roc_auc_score','full'] = roc\n",
    "    df.loc['f1_score', 'full'] = f1\n",
    "    df['type'] = p\n",
    "    full_results = pd.concat([full_results, df], axis=0)\n",
    "\n",
    "\n",
    "full_results.set_index('type', append=True, inplace=True)\n",
    "\n",
    "full_results = full_results.reorder_levels(['type',0])\n",
    "full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "01780ac9-66c6-4318-b9c5-ec2d517d0196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_results = pd.concat([full_results, reduced_results], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2aa31136-f47d-483e-bcde-76204a80e686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>full</th>\n",
       "      <th>reduced</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">conservative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.473393</td>\n",
       "      <td>0.495446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.442105</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">balanced</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.512834</td>\n",
       "      <td>0.503922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">growth</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.514452</td>\n",
       "      <td>0.563332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.532967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">aggressive</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.545075</td>\n",
       "      <td>0.534421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.530055</td>\n",
       "      <td>0.611227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">alternative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.519740</td>\n",
       "      <td>0.548462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.619835</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                full   reduced\n",
       "type                                          \n",
       "conservative roc_auc_score  0.473393  0.495446\n",
       "             f1_score       0.442105  0.484848\n",
       "balanced     roc_auc_score  0.512834  0.503922\n",
       "             f1_score       0.466019  0.500000\n",
       "growth       roc_auc_score  0.514452  0.563332\n",
       "             f1_score       0.615385  0.532967\n",
       "aggressive   roc_auc_score  0.545075  0.534421\n",
       "             f1_score       0.530055  0.611227\n",
       "alternative  roc_auc_score  0.519740  0.548462\n",
       "             f1_score       0.619835  0.658228"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f15ac57-7167-4f33-a62e-477d72aee987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2ed12_row0_col1, #T_2ed12_row1_col1, #T_2ed12_row2_col0, #T_2ed12_row3_col1, #T_2ed12_row4_col1, #T_2ed12_row5_col0, #T_2ed12_row6_col0, #T_2ed12_row7_col1, #T_2ed12_row8_col1, #T_2ed12_row9_col1 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2ed12\">\n",
       "  <caption>Metrics Comparison for All Models</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2ed12_level0_col0\" class=\"col_heading level0 col0\" >full</th>\n",
       "      <th id=\"T_2ed12_level0_col1\" class=\"col_heading level0 col1\" >reduced</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >type</th>\n",
       "      <th class=\"index_name level1\" >&nbsp;</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2ed12_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">conservative</th>\n",
       "      <th id=\"T_2ed12_level1_row0\" class=\"row_heading level1 row0\" >roc_auc_score</th>\n",
       "      <td id=\"T_2ed12_row0_col0\" class=\"data row0 col0\" >0.473393</td>\n",
       "      <td id=\"T_2ed12_row0_col1\" class=\"data row0 col1\" >0.495446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ed12_level1_row1\" class=\"row_heading level1 row1\" >f1_score</th>\n",
       "      <td id=\"T_2ed12_row1_col0\" class=\"data row1 col0\" >0.442105</td>\n",
       "      <td id=\"T_2ed12_row1_col1\" class=\"data row1 col1\" >0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ed12_level0_row2\" class=\"row_heading level0 row2\" rowspan=\"2\">balanced</th>\n",
       "      <th id=\"T_2ed12_level1_row2\" class=\"row_heading level1 row2\" >roc_auc_score</th>\n",
       "      <td id=\"T_2ed12_row2_col0\" class=\"data row2 col0\" >0.512834</td>\n",
       "      <td id=\"T_2ed12_row2_col1\" class=\"data row2 col1\" >0.503922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ed12_level1_row3\" class=\"row_heading level1 row3\" >f1_score</th>\n",
       "      <td id=\"T_2ed12_row3_col0\" class=\"data row3 col0\" >0.466019</td>\n",
       "      <td id=\"T_2ed12_row3_col1\" class=\"data row3 col1\" >0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ed12_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"2\">growth</th>\n",
       "      <th id=\"T_2ed12_level1_row4\" class=\"row_heading level1 row4\" >roc_auc_score</th>\n",
       "      <td id=\"T_2ed12_row4_col0\" class=\"data row4 col0\" >0.514452</td>\n",
       "      <td id=\"T_2ed12_row4_col1\" class=\"data row4 col1\" >0.563332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ed12_level1_row5\" class=\"row_heading level1 row5\" >f1_score</th>\n",
       "      <td id=\"T_2ed12_row5_col0\" class=\"data row5 col0\" >0.615385</td>\n",
       "      <td id=\"T_2ed12_row5_col1\" class=\"data row5 col1\" >0.532967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ed12_level0_row6\" class=\"row_heading level0 row6\" rowspan=\"2\">aggressive</th>\n",
       "      <th id=\"T_2ed12_level1_row6\" class=\"row_heading level1 row6\" >roc_auc_score</th>\n",
       "      <td id=\"T_2ed12_row6_col0\" class=\"data row6 col0\" >0.545075</td>\n",
       "      <td id=\"T_2ed12_row6_col1\" class=\"data row6 col1\" >0.534421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ed12_level1_row7\" class=\"row_heading level1 row7\" >f1_score</th>\n",
       "      <td id=\"T_2ed12_row7_col0\" class=\"data row7 col0\" >0.530055</td>\n",
       "      <td id=\"T_2ed12_row7_col1\" class=\"data row7 col1\" >0.611227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ed12_level0_row8\" class=\"row_heading level0 row8\" rowspan=\"2\">alternative</th>\n",
       "      <th id=\"T_2ed12_level1_row8\" class=\"row_heading level1 row8\" >roc_auc_score</th>\n",
       "      <td id=\"T_2ed12_row8_col0\" class=\"data row8 col0\" >0.519740</td>\n",
       "      <td id=\"T_2ed12_row8_col1\" class=\"data row8 col1\" >0.548462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ed12_level1_row9\" class=\"row_heading level1 row9\" >f1_score</th>\n",
       "      <td id=\"T_2ed12_row9_col0\" class=\"data row9 col0\" >0.619835</td>\n",
       "      <td id=\"T_2ed12_row9_col1\" class=\"data row9 col1\" >0.658228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b8896070>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.style.highlight_max(color='lightblue', axis = 1).set_caption(\"Metrics Comparison for All Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "74316961-c73a-4b5c-9a7d-3b95f79994fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best = all_results[['reduced']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3c943383-4b26-47f9-a2bf-17ec0e2c50cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "96f65f23-2c1e-442a-b993-76ec66876a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best.to_csv(Path(\"./model_metrics/nn.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b89598-26e2-4739-bb31-e3651af20075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e5153-1cd5-4dbd-bdf8-e8e086fe2798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
