{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00c932f-585c-4efa-a4ba-04812d17cced",
   "metadata": {},
   "source": [
    "set seeds for reproducible results then import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a30c92f-a14c-4ef7-8723-34101c2380a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 10:45:16.037336: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# from numpy.random import seed\n",
    "# seed(1)\n",
    "# from tensorflow import set_random_seed\n",
    "# set_random_seed(2)\n",
    "\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e5fda7-1a73-4584-8af9-1c2f34aa0926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.3.2/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"tabulator\"], function(Tabulator) {\n",
       "\twindow.Tabulator = Tabulator\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"moment\"], function(moment) {\n",
       "\twindow.moment = moment\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 4;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n",
       "    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/js/tabulator.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/gridstack/gridstack@4.2.5/dist/gridstack-h5.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.14.4/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var css_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/css/tabulator_simple.min.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/debugger.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/alerts.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/card.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/widgets.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/markdown.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/json.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/loading.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/dataframe.css\"];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      inject_raw_css(\"\\n    .bk.pn-loading.arc:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n",
       "    },    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, js_modules, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.3.2/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 4;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/gridstack/gridstack@4.2.5/dist/gridstack-h5.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.14.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/css/tabulator_simple.min.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/debugger.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/alerts.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/card.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/widgets.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/markdown.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/json.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/loading.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/dataframe.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arc:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.bk-root, .bk-root .bk:before, .bk-root .bk:after {\n",
       "  font-family: var(--jp-ui-font-size1);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import modules\n",
    "import panel as pn\n",
    "pn.extension('tabulator')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from panel.template import FastListTemplate\n",
    "from pathlib import Path\n",
    "#from yahoo_fin.stock_info import get_data\n",
    "import datetime\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# import modules that help build tabs\n",
    "#import modules.helpers as helpers\n",
    "#import modules.HistoricalData as hst\n",
    "#import modules.MCTab as MCTab\n",
    "#import modules.intro as intro\n",
    "#import modules.profile as prf\n",
    "#import modules.algorithmic_functions as af\n",
    "\n",
    "\n",
    "#import pandas_ta as ta\n",
    "#import yfinance as yf\n",
    "# import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras_tuner as kt\n",
    "\n",
    "#from pandas.tseries.offsets import DateOffset\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "#import seaborn as sns\n",
    "\n",
    "#from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278db87f-540c-4d6d-bb58-cd9bc8c2f229",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd137c6-1625-4288-b3c7-67f22040bf72",
   "metadata": {},
   "source": [
    "## *Data has been preprocessed*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a02c345-5d22-41df-82aa-240e5e5550f3",
   "metadata": {},
   "source": [
    "\n",
    "* Load the test/train datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5eaa51-b5de-48a7-ac70-ef41639dcfad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the portfolios being used\n",
    "portfolios = ['conservative', 'balanced', 'growth', 'aggressive','alternative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984dcb3e-8ad7-4c20-8673-4be088f9cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load X_train_full and X_test_full\n",
    "X_train_full_conservative = pd.read_csv(Path(\"./data/X_train_full_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_conservative = pd.read_csv(Path(\"./data/X_test_full_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_balanced = pd.read_csv(Path(\"./data/X_train_full_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_balanced = pd.read_csv(Path(\"./data/X_test_full_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_growth = pd.read_csv(Path(\"./data/X_train_full_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_growth = pd.read_csv(Path(\"./data/X_test_full_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_aggressive = pd.read_csv(Path(\"./data/X_train_full_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_aggressive = pd.read_csv(Path(\"./data/X_test_full_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_full_alternative = pd.read_csv(Path(\"./data/X_train_full_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_full_alternative = pd.read_csv(Path(\"./data/X_test_full_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "\n",
    "\n",
    "#load y_train and y_test\n",
    "y_train_conservative = pd.read_csv(Path(\"./data/y_train_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_conservative = pd.read_csv(Path(\"./data/y_test_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_balanced = pd.read_csv(Path(\"./data/y_train_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_balanced = pd.read_csv(Path(\"./data/y_test_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_growth = pd.read_csv(Path(\"./data/y_train_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_growth = pd.read_csv(Path(\"./data/y_test_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_aggressive = pd.read_csv(Path(\"./data/y_train_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_aggressive = pd.read_csv(Path(\"./data/y_test_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_alternative = pd.read_csv(Path(\"./data/y_train_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_alternative = pd.read_csv(Path(\"./data/y_test_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "datafiles_full = {'conservative': [X_train_full_conservative,\n",
    "                              X_test_full_conservative, \n",
    "                              y_train_conservative, \n",
    "                              y_test_conservative],\n",
    "            'balanced': [X_train_full_balanced,\n",
    "                              X_test_full_balanced, \n",
    "                              y_train_balanced, \n",
    "                              y_test_balanced],\n",
    "            'growth': [X_train_full_growth,\n",
    "                              X_test_full_growth, \n",
    "                              y_train_growth, \n",
    "                              y_test_growth],\n",
    "            'aggressive': [X_train_full_aggressive,\n",
    "                              X_test_full_aggressive, \n",
    "                              y_train_aggressive, \n",
    "                              y_test_aggressive],\n",
    "            'alternative': [X_train_full_alternative,\n",
    "                              X_test_full_alternative, \n",
    "                              y_train_alternative, \n",
    "                              y_test_alternative]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e29412-4965-4d1e-b95c-4c4f78cd2334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load X_train_reduced and X_test_reduced\n",
    "X_train_reduced_conservative = pd.read_csv(Path(\"./data/X_train_reduced_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_conservative = pd.read_csv(Path(\"./data/X_test_reduced_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_balanced = pd.read_csv(Path(\"./data/X_train_reduced_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_balanced = pd.read_csv(Path(\"./data/X_test_reduced_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_growth = pd.read_csv(Path(\"./data/X_train_reduced_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_growth = pd.read_csv(Path(\"./data/X_test_reduced_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_aggressive = pd.read_csv(Path(\"./data/X_train_reduced_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_aggressive = pd.read_csv(Path(\"./data/X_test_reduced_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "X_train_reduced_alternative = pd.read_csv(Path(\"./data/X_train_reduced_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "X_test_reduced_alternative = pd.read_csv(Path(\"./data/X_test_reduced_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "\n",
    "\n",
    "#load y_train and y_test\n",
    "y_train_conservative = pd.read_csv(Path(\"./data/y_train_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_conservative = pd.read_csv(Path(\"./data/y_test_conservative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_balanced = pd.read_csv(Path(\"./data/y_train_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_balanced = pd.read_csv(Path(\"./data/y_test_balanced.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_growth = pd.read_csv(Path(\"./data/y_train_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_growth = pd.read_csv(Path(\"./data/y_test_growth.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_aggressive = pd.read_csv(Path(\"./data/y_train_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_aggressive = pd.read_csv(Path(\"./data/y_test_aggressive.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "y_train_alternative = pd.read_csv(Path(\"./data/y_train_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "y_test_alternative = pd.read_csv(Path(\"./data/y_test_alternative.csv\"), index_col=\"Unnamed: 0\", parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "datafiles_reduced = {'conservative': [X_train_reduced_conservative,\n",
    "                              X_test_reduced_conservative, \n",
    "                              y_train_conservative, \n",
    "                              y_test_conservative],\n",
    "            'balanced': [X_train_reduced_balanced,\n",
    "                              X_test_reduced_balanced, \n",
    "                              y_train_balanced, \n",
    "                              y_test_balanced],\n",
    "            'growth': [X_train_reduced_growth,\n",
    "                              X_test_reduced_growth, \n",
    "                              y_train_growth, \n",
    "                              y_test_growth],\n",
    "            'aggressive': [X_train_reduced_aggressive,\n",
    "                              X_test_reduced_aggressive, \n",
    "                              y_train_aggressive, \n",
    "                              y_test_aggressive],\n",
    "            'alternative': [X_train_reduced_alternative,\n",
    "                              X_test_reduced_alternative, \n",
    "                              y_train_alternative, \n",
    "                              y_test_alternative]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3bc2b6-819e-49ca-9794-dee3868329e8",
   "metadata": {},
   "source": [
    "## Use Hyperband to determine optimal parameters for layer units, layer activations and optimizer learning rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eedade-be0f-429a-b3f5-cfa328d57a01",
   "metadata": {},
   "source": [
    "### Run for full feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c528993-79a0-44ed-b49b-74b59010475a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from ./hp/hp_conservative/tuner0.json\n",
      "now running tuner search for conservative\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Tuner from ./hp/hp_balanced/tuner0.json\n",
      "now running tuner search for balanced\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Tuner from ./hp/hp_growth/tuner0.json\n",
      "now running tuner search for growth\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Tuner from ./hp/hp_aggressive/tuner0.json\n",
      "now running tuner search for aggressive\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "INFO:tensorflow:Reloading Tuner from ./hp/hp_alternative/tuner0.json\n",
      "now running tuner search for alternative\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_full = pd.DataFrame()\n",
    "X_scaler = StandardScaler()\n",
    "for p in portfolios:\n",
    "    X_train = datafiles_full[p][0]\n",
    "    X_test = datafiles_full[p][1]\n",
    "    y_train = datafiles_full[p][2]\n",
    "    y_test = datafiles_full[p][3]\n",
    "    \n",
    "    scaler = X_scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    number_input_features = 18\n",
    "    def model_builder(hp):\n",
    "\n",
    "        hp_units = hp.Int('units', min_value=6, max_value=36, step=2)\n",
    "        hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "        hp_units2 = hp.Int('units2', min_value=3, max_value=18, step=2)\n",
    "        hp_activation2 = hp.Choice('activation2', values=['relu', 'tanh'])\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=hp_units, input_dim=number_input_features, activation=hp_activation))\n",
    "        model.add(Dense(units=hp_units2, activation=hp_activation2))\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    tuner = kt.Hyperband(model_builder, objective='val_accuracy',\n",
    "                 max_epochs=100,\n",
    "                 factor=3,\n",
    "                 directory='./hp',\n",
    "                 project_name=f\"hp_{p}\")\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    print(f\"now running tuner search for {p}\")\n",
    "    tuner.search(X_train_scaled, y_train, epochs=100, validation_split=0.2, callbacks=[stop_early], verbose=0)\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_unit1 = best_hps.get('units')\n",
    "    best_unit2 = best_hps.get('units2') \n",
    "    best_activation1 =  best_hps.get('activation')\n",
    "    best_activation2 = best_hps.get('activation2')\n",
    "    best_learning_rate = best_hps.get('learning_rate')\n",
    "\n",
    "    best_dict = {'units1': best_unit1,\n",
    "                 'units2': best_unit2,\n",
    "                 'activation1': best_activation1,\n",
    "                 'activation2': best_activation2,\n",
    "                 'learning_rate': best_learning_rate}\n",
    "\n",
    "    best_parameters = pd.DataFrame.from_dict(best_dict, orient='index', columns=[f\"{p}\"])\n",
    "    results_full = pd.concat([results_full, best_parameters], axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e2c569-b222-4730-ba31-11d57473fe08",
   "metadata": {},
   "source": [
    "### Run for reduced feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdfef671-174c-4c85-bb46-8efd2906ecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from ./hp/hp__reduced_conservative/tuner0.json\n",
      "now running tuner search for conservative\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for conservative are:\n",
      "units1 26\n",
      "units2 3\n",
      "activation1 relu\n",
      "activation2 tanh\n",
      "learning_rate 0.01\n",
      "INFO:tensorflow:Reloading Tuner from ./hp/hp__reduced_balanced/tuner0.json\n",
      "now running tuner search for balanced\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for balanced are:\n",
      "units1 32\n",
      "units2 3\n",
      "activation1 tanh\n",
      "activation2 tanh\n",
      "learning_rate 0.01\n",
      "INFO:tensorflow:Reloading Tuner from ./hp/hp__reduced_growth/tuner0.json\n",
      "now running tuner search for growth\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for growth are:\n",
      "units1 36\n",
      "units2 3\n",
      "activation1 tanh\n",
      "activation2 tanh\n",
      "learning_rate 0.001\n",
      "INFO:tensorflow:Reloading Tuner from ./hp/hp__reduced_aggressive/tuner0.json\n",
      "now running tuner search for aggressive\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for aggressive are:\n",
      "units1 34\n",
      "units2 3\n",
      "activation1 tanh\n",
      "activation2 relu\n",
      "learning_rate 0.01\n",
      "INFO:tensorflow:Reloading Tuner from ./hp/hp__reduced_alternative/tuner0.json\n",
      "now running tuner search for alternative\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "best values for alternative are:\n",
      "units1 30\n",
      "units2 3\n",
      "activation1 relu\n",
      "activation2 tanh\n",
      "learning_rate 0.01\n"
     ]
    }
   ],
   "source": [
    "X_scaler = StandardScaler()\n",
    "results_reduced = pd.DataFrame()\n",
    "for p in portfolios:\n",
    "    X_train = datafiles_reduced[p][0]\n",
    "    X_test = datafiles_reduced[p][1]\n",
    "    y_train = datafiles_reduced[p][2]\n",
    "    y_test = datafiles_reduced[p][3]\n",
    "    \n",
    "    scaler = X_scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    number_input_features = 7\n",
    "    def model_builder(hp):\n",
    "\n",
    "        hp_units = hp.Int('units', min_value=6, max_value=36, step=2)\n",
    "        hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "        hp_units2 = hp.Int('units2', min_value=3, max_value=18, step=2)\n",
    "        hp_activation2 = hp.Choice('activation2', values=['relu', 'tanh'])\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=hp_units, input_dim=number_input_features, activation=hp_activation))\n",
    "        model.add(Dense(units=hp_units2, activation=hp_activation2))\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    tuner = kt.Hyperband(model_builder, objective='val_accuracy',\n",
    "                 max_epochs=100,\n",
    "                 factor=3,\n",
    "                 directory='./hp',\n",
    "                 project_name=f\"hp__reduced_{p}\")\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    print(f\"now running tuner search for {p}\")\n",
    "    tuner.search(X_train_scaled, y_train, epochs=100, validation_split=0.2, callbacks=[stop_early], verbose=0)\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_unit1 = best_hps.get('units')\n",
    "    best_unit2 = best_hps.get('units2') \n",
    "    best_activation1 =  best_hps.get('activation')\n",
    "    best_activation2 = best_hps.get('activation2')\n",
    "    best_learning_rate = best_hps.get('learning_rate')\n",
    "\n",
    "    best_dict = {'units1': best_unit1,\n",
    "                 'units2': best_unit2,\n",
    "                 'activation1': best_activation1,\n",
    "                 'activation2': best_activation2,\n",
    "                 'learning_rate': best_learning_rate}\n",
    "     \n",
    "    print(f\"best values for {p} are:\")\n",
    "    for k,v in best_dict.items():\n",
    "        print(k, v)\n",
    "\n",
    "    best_parameters = pd.DataFrame.from_dict(best_dict, orient='index', columns=[f\"{p}\"])\n",
    "    results_reduced = pd.concat([results_reduced, best_parameters], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb86a0a-25ff-4a39-b848-9aa192f6de07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c988d-de47-4f1a-89fd-f6a041ef2512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a7ef0-34d7-4aa7-a469-6fd3f4d3138c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1715d-aa56-4e2a-a508-4c02a9a4d097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd464d47-6bd4-470d-8f74-b26c1f268cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d71d9ca1-ce94-49d9-9bf4-664fb2bd7cb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24651f9e-befd-48d7-a988-bc66f4247344",
   "metadata": {},
   "source": [
    "## Use best parameters from tuning notebook to train one model per portfolio class for both the full and reduced feature sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749223c0-e99f-46af-8b11-d9b80ce163e7",
   "metadata": {},
   "source": [
    "### Full Feature Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057a8d4-b6e7-46f1-a72c-a677b61e50a8",
   "metadata": {},
   "source": [
    "## *Conservative Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb703c7b-c1a6-466f-ad85-d847a9c5133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 10:45:38.142430: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.9734 - accuracy: 0.5257 - 116ms/epoch - 14ms/step\n",
      "Loss: 0.9734028577804565, Accuracy: 0.5256916880607605\n"
     ]
    }
   ],
   "source": [
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = results_full.loc['units1', 'conservative']\n",
    "hidden_nodes_layer2 = results_full.loc['units2', 'conservative']\n",
    "activation_1 = results_full.loc['activation1', 'conservative']\n",
    "activation_2 = results_full.loc['activation2', 'conservative']\n",
    "lr = results_full.loc['learning_rate', 'conservative']\n",
    "\n",
    "\n",
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_conservative)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_conservative_scaled = X_scaler.transform(X_train_full_conservative)\n",
    "X_test_full_conservative_scaled = X_scaler.transform(X_test_full_conservative)\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_conservative = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_conservative.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_conservative.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_conservative.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_conservative.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "deep_net_conservative_model = nn_conservative.fit(X_train_full_conservative_scaled, y_train_conservative, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Conservative Model using testing data\n",
    "model_loss, model_accuracy = nn_conservative.evaluate(X_test_full_conservative_scaled, y_test_conservative, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a163e2-8926-480e-b4b6-45cb71a91f46",
   "metadata": {},
   "source": [
    "## *Balanced Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192b72d1-119f-460e-b58b-f8b5c142b599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.7006 - accuracy: 0.5375 - 84ms/epoch - 11ms/step\n",
      "Loss: 0.7005859613418579, Accuracy: 0.5375494360923767\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_balanced)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_balanced_scaled = X_scaler.transform(X_train_full_balanced)\n",
    "X_test_full_balanced_scaled = X_scaler.transform(X_test_full_balanced)\n",
    "\n",
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = results_full.loc['units1', 'balanced']\n",
    "hidden_nodes_layer2 = results_full.loc['units2', 'balanced']\n",
    "activation_1 = results_full.loc['activation1', 'balanced']\n",
    "activation_2 = results_full.loc['activation2', 'balanced']\n",
    "lr = results_full.loc['learning_rate', 'balanced']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_balanced = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_balanced.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_balanced.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_balanced.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_balanced.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_balanced_model = nn_balanced.fit(X_train_full_balanced_scaled, y_train_balanced, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Balanced Model using testing data\n",
    "model_loss, model_accuracy = nn_balanced.evaluate(X_test_full_balanced_scaled, y_test_balanced, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae2329-87bc-4499-98b8-3d963e35b26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19f33763-0668-431b-95c0-ca56ca94a4ec",
   "metadata": {},
   "source": [
    "## *Growth Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "429921b6-fdd3-4b92-ae10-68c041ad7662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 1.1315 - accuracy: 0.5060 - 96ms/epoch - 12ms/step\n",
      "Loss: 1.1314703226089478, Accuracy: 0.5059760808944702\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_growth)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_growth_scaled = X_scaler.transform(X_train_full_growth)\n",
    "X_test_full_growth_scaled = X_scaler.transform(X_test_full_growth)\n",
    "\n",
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = results_full.loc['units1', 'growth']\n",
    "hidden_nodes_layer2 = results_full.loc['units2', 'growth']\n",
    "activation_1 = results_full.loc['activation1', 'growth']\n",
    "activation_2 = results_full.loc['activation2', 'growth']\n",
    "lr = results_full.loc['learning_rate', 'growth']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_growth = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_growth.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_growth.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_growth.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_growth.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_growth_model = nn_growth.fit(X_train_full_growth_scaled, y_train_growth, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Growth Model using testing data\n",
    "model_loss, model_accuracy = nn_growth.evaluate(X_test_full_growth_scaled, y_test_growth, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c17114-71e2-4289-b81f-249908d1cb4f",
   "metadata": {},
   "source": [
    "## *Aggressive Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1dc6a4b-2b7c-4c05-981f-116fd683c6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.6909 - accuracy: 0.5339 - 96ms/epoch - 12ms/step\n",
      "Loss: 0.6908626556396484, Accuracy: 0.5338645577430725\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_aggressive)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_aggressive_scaled = X_scaler.transform(X_train_full_aggressive)\n",
    "X_test_full_aggressive_scaled = X_scaler.transform(X_test_full_aggressive)\n",
    "\n",
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = results_full.loc['units1', 'aggressive']\n",
    "hidden_nodes_layer2 = results_full.loc['units2', 'aggressive']\n",
    "activation_1 = results_full.loc['activation1', 'aggressive']\n",
    "activation_2 = results_full.loc['activation2', 'aggressive']\n",
    "lr = results_full.loc['learning_rate', 'aggressive']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_aggressive = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_aggressive.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_aggressive.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_aggressive.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_aggressive.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_aggressive_model = nn_aggressive.fit(X_train_full_aggressive_scaled, y_train_aggressive, epochs=100, verbose=0)\n",
    "\n",
    "model_loss, model_accuracy = nn_aggressive.evaluate(X_test_full_aggressive_scaled, y_test_aggressive, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84757b60-fdd1-414d-aa6b-f304caf0ac2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86119757-cb41-45b1-b564-1a99e05ea7c9",
   "metadata": {},
   "source": [
    "## Alternative Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1371932a-6738-4e65-92eb-8aa37b1efc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_full_alternative)\n",
    "\n",
    "# Scale the data\n",
    "X_train_full_alternative_scaled = X_scaler.transform(X_train_full_alternative)\n",
    "X_test_full_alternative_scaled = X_scaler.transform(X_test_full_alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea08b4e6-2222-4de8-afbd-9a4cdf8fd28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 1.2620 - accuracy: 0.5100 - 165ms/epoch - 21ms/step\n",
      "Loss: 1.2619696855545044, Accuracy: 0.5099601745605469\n"
     ]
    }
   ],
   "source": [
    "number_input_features = 18\n",
    "hidden_nodes_layer1 = results_full.loc['units1', 'alternative']\n",
    "hidden_nodes_layer2 = results_full.loc['units2', 'alternative']\n",
    "activation_1 = results_full.loc['activation1', 'alternative']\n",
    "activation_2 = results_full.loc['activation2', 'alternative']\n",
    "lr = results_full.loc['learning_rate', 'alternative']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_alternative = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_alternative.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_alternative.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_alternative.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_alternative.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_alternative_model = nn_alternative.fit(X_train_full_alternative_scaled, y_train_alternative, epochs=100, verbose=0)\n",
    "\n",
    "model_loss, model_accuracy = nn_alternative.evaluate(X_test_full_alternative_scaled, y_test_alternative, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d725da9b-31bc-436f-988a-c0d7a5aab4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conservative Model\n",
      "Loss: 0.9734028577804565, Accuracy: 0.5256916880607605\n",
      "\n",
      "Balanced Model\n",
      "Loss: 0.7005859613418579, Accuracy: 0.5375494360923767\n",
      "\n",
      "Growth Model\n",
      "Loss: 1.1314703226089478, Accuracy: 0.5059760808944702\n",
      "\n",
      "Aggressive Model\n",
      "Loss: 0.6908626556396484, Accuracy: 0.5338645577430725\n",
      "\n",
      "Alternative Model\n",
      "Loss: 1.2619696855545044, Accuracy: 0.5099601745605469\n"
     ]
    }
   ],
   "source": [
    "#Conservative Portfolio\n",
    "# deep_net_conservative_model = nn_conservative.fit(X_train_full_conservative_scaled, y_train_conservative, epochs=100)\n",
    "\n",
    "# Evaluate Conservative Model using testing data\n",
    "model_loss, model_accuracy = nn_conservative.evaluate(X_test_full_conservative_scaled, y_test_conservative, verbose=0)\n",
    "\n",
    "print(f\"\\nConservative Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "#Balanced Portfolio\n",
    "# deep_net_balanced_model = nn_balanced.fit(X_train_full_balanced_scaled, y_train_balanced, epochs=100)\n",
    "\n",
    "#Evaluate Balanced Model using testing data\n",
    "model_loss, model_accuracy = nn_balanced.evaluate(X_test_full_balanced_scaled, y_test_balanced, verbose=0)\n",
    "\n",
    "print(f\"\\nBalanced Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#Growth Portfolio\n",
    "# deep_net_growth_model = nn_growth.fit(X_train_full_growth_scaled, y_train_growth, epochs=100)\n",
    "\n",
    "#Evaluate Growth Model using testing data\n",
    "model_loss, model_accuracy = nn_growth.evaluate(X_test_full_growth_scaled, y_test_growth, verbose=0)\n",
    "\n",
    "print(f\"\\nGrowth Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "#Aggressive Portfolio\n",
    "# deep_net_aggressive_model = nn_aggressive.fit(X_train_full_aggressive_scaled, y_train_aggressive, epochs=100)\n",
    "\n",
    "#Evaluate Aggressive Model using testing data\n",
    "model_loss, model_accuracy = nn_aggressive.evaluate(X_test_full_aggressive_scaled, y_test_aggressive, verbose=0)\n",
    "\n",
    "print(f\"\\nAggressive Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#Alternative Portfolio\n",
    "# deep_net_alternative_model = nn_alternative.fit(X_train_full_alternative_scaled, y_train_alternative, epochs=100)\n",
    "\n",
    "#Evaluate Alternative Model using testing data\n",
    "model_loss, model_accuracy = nn_alternative.evaluate(X_test_full_alternative_scaled, y_test_alternative, verbose=0)\n",
    "\n",
    "print(f\"\\nAlternative Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ee494-ab1c-44f9-bc2c-a9f91e17c3c6",
   "metadata": {},
   "source": [
    "### Make predictions using trained models. Save both class predicitions and prediction probabiities for evaluation score calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5526b79-1d35-4828-9dcd-1aee8b5f0eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 899us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 933us/step\n",
      "8/8 [==============================] - 0s 802us/step\n",
      "8/8 [==============================] - 0s 871us/step\n"
     ]
    }
   ],
   "source": [
    "full_alternative_proba = nn_alternative.predict(X_test_full_alternative_scaled)\n",
    "full_aggressive_proba = nn_aggressive.predict(X_test_full_aggressive_scaled)\n",
    "full_growth_proba = nn_growth.predict(X_test_full_growth_scaled)\n",
    "full_balanced_proba = nn_balanced.predict(X_test_full_balanced_scaled)\n",
    "full_conservative_proba = nn_conservative.predict(X_test_full_conservative_scaled)\n",
    "\n",
    "full_alternative_preds = tf.cast(full_alternative_proba >= 0.5, tf.int32)\n",
    "full_aggressive_preds = tf.cast(full_aggressive_proba >= 0.5, tf.int32)\n",
    "full_growth_preds = tf.cast(full_growth_proba >= 0.5, tf.int32)\n",
    "full_balanced_preds = tf.cast(full_balanced_proba >= 0.5, tf.int32)\n",
    "full_conservative_preds = tf.cast(full_conservative_proba >= 0.5, tf.int32)\n",
    "\n",
    "full_preds = {'alternative': [full_alternative_proba, full_alternative_preds],\n",
    "              'aggressive': [full_aggressive_proba, full_aggressive_preds],\n",
    "              'growth': [full_growth_proba, full_growth_preds],\n",
    "              'balanced': [full_balanced_proba, full_balanced_preds],\n",
    "              'conservative': [full_conservative_proba, full_conservative_preds]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1625d3-9741-459a-b8f3-503cb6711c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd248f-d75e-4a5f-be0f-5075049b98eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c91004-8425-4f41-83d5-ca723b2b0e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bf8ae-65e3-4cc4-af00-b07fa5a71b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "569b287a-37e1-4f48-8369-a7073b9e43b2",
   "metadata": {},
   "source": [
    "### Reduced Feature Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2fdda6-df30-4d45-92ba-bbaca5b38df5",
   "metadata": {},
   "source": [
    "## *Conservative Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fe604bd-5953-40cd-85d5-dbc51ff13d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.7132 - accuracy: 0.5415 - 129ms/epoch - 16ms/step\n",
      "Loss: 0.7131738066673279, Accuracy: 0.5415019989013672\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_conservative)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_conservative_scaled = X_scaler.transform(X_train_reduced_conservative)\n",
    "X_test_reduced_conservative_scaled = X_scaler.transform(X_test_reduced_conservative)\n",
    "\n",
    "\n",
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = results_reduced.loc['units1', 'conservative']\n",
    "hidden_nodes_layer2 = results_reduced.loc['units2', 'conservative']\n",
    "activation_1 = results_reduced.loc['activation1', 'conservative']\n",
    "activation_2 = results_reduced.loc['activation2', 'conservative']\n",
    "lr = results_reduced.loc['learning_rate', 'conservative']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_conservative = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_conservative.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_conservative.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_conservative.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_conservative.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "deep_net_conservative_model = nn_conservative.fit(X_train_reduced_conservative_scaled, y_train_conservative, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Conservative Model using testing data\n",
    "model_loss, model_accuracy = nn_conservative.evaluate(X_test_reduced_conservative_scaled, y_test_conservative, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2802a3c-f7be-48d7-ba3b-51217b9aa5c4",
   "metadata": {},
   "source": [
    "## *Balanced Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b534977d-d76f-496e-953a-cd29a6855f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.8444 - accuracy: 0.5375 - 102ms/epoch - 13ms/step\n",
      "Loss: 0.8443578481674194, Accuracy: 0.5375494360923767\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_balanced)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_balanced_scaled = X_scaler.transform(X_train_reduced_balanced)\n",
    "X_test_reduced_balanced_scaled = X_scaler.transform(X_test_reduced_balanced)\n",
    "\n",
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = results_reduced.loc['units1', 'balanced']\n",
    "hidden_nodes_layer2 = results_reduced.loc['units2', 'balanced']\n",
    "activation_1 = results_reduced.loc['activation1', 'balanced']\n",
    "activation_2 = results_reduced.loc['activation2', 'balanced']\n",
    "lr = results_reduced.loc['learning_rate', 'balanced']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_balanced = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_balanced.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_balanced.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_balanced.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_balanced.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_balanced_model = nn_balanced.fit(X_train_reduced_balanced_scaled, y_train_balanced, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Balanced Model using testing data\n",
    "model_loss, model_accuracy = nn_balanced.evaluate(X_test_reduced_balanced_scaled, y_test_balanced, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d6480-2919-4841-acc8-c64d37c5bc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d744e0c-4935-471f-b077-a49a109909f9",
   "metadata": {},
   "source": [
    "## *Growth Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "627eeef1-a42e-47e5-8fa0-e9959e5f9b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.7940 - accuracy: 0.5378 - 89ms/epoch - 11ms/step\n",
      "Loss: 0.7939696311950684, Accuracy: 0.5378485918045044\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_growth)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_growth_scaled = X_scaler.transform(X_train_reduced_growth)\n",
    "X_test_reduced_growth_scaled = X_scaler.transform(X_test_reduced_growth)\n",
    "\n",
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = results_reduced.loc['units1', 'growth']\n",
    "hidden_nodes_layer2 = results_reduced.loc['units2', 'growth']\n",
    "activation_1 = results_reduced.loc['activation1', 'growth']\n",
    "activation_2 = results_reduced.loc['activation2', 'growth']\n",
    "lr = results_reduced.loc['learning_rate', 'growth']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_growth = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_growth.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_growth.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_growth.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_growth.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_growth_model = nn_growth.fit(X_train_reduced_growth_scaled, y_train_growth, epochs=100, verbose=0)\n",
    "\n",
    "# Evaluate Growth Model using testing data\n",
    "model_loss, model_accuracy = nn_growth.evaluate(X_test_reduced_growth_scaled, y_test_growth, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f64ac-82e7-4c75-b012-d55977c6866a",
   "metadata": {},
   "source": [
    "## *Aggressive Portfolio*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af15b3fd-1c41-4ca8-96d0-120b78b3f805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.7353 - accuracy: 0.5020 - 92ms/epoch - 12ms/step\n",
      "Loss: 0.7352592349052429, Accuracy: 0.5019920468330383\n"
     ]
    }
   ],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_aggressive)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_aggressive_scaled = X_scaler.transform(X_train_reduced_aggressive)\n",
    "X_test_reduced_aggressive_scaled = X_scaler.transform(X_test_reduced_aggressive)\n",
    "\n",
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = results_reduced.loc['units1', 'aggressive']\n",
    "hidden_nodes_layer2 = results_reduced.loc['units2', 'aggressive']\n",
    "activation_1 = results_reduced.loc['activation1', 'aggressive']\n",
    "activation_2 = results_reduced.loc['activation2', 'aggressive']\n",
    "lr = results_reduced.loc['learning_rate', 'aggressive']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_aggressive = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_aggressive.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_aggressive.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_aggressive.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_aggressive.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_aggressive_model = nn_aggressive.fit(X_train_reduced_aggressive_scaled, y_train_aggressive, epochs=100, verbose=0)\n",
    "\n",
    "model_loss, model_accuracy = nn_aggressive.evaluate(X_test_reduced_aggressive_scaled, y_test_aggressive, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355dc408-8d00-4f08-8ac5-755ab308d979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88ab6ec9-4596-4b0b-bbcb-6154a727cf63",
   "metadata": {},
   "source": [
    "## Alternative Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eca1f350-df35-4498-b481-80b33d08d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train_reduced_alternative)\n",
    "\n",
    "# Scale the data\n",
    "X_train_reduced_alternative_scaled = X_scaler.transform(X_train_reduced_alternative)\n",
    "X_test_reduced_alternative_scaled = X_scaler.transform(X_test_reduced_alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe9f915a-f8f3-4039-b803-e12f964de789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 0.7516 - accuracy: 0.5339 - 154ms/epoch - 19ms/step\n",
      "Loss: 0.7515614628791809, Accuracy: 0.5338645577430725\n"
     ]
    }
   ],
   "source": [
    "number_input_features = 7\n",
    "hidden_nodes_layer1 = results_reduced.loc['units1', 'alternative']\n",
    "hidden_nodes_layer2 = results_reduced.loc['units2', 'alternative']\n",
    "activation_1 = results_reduced.loc['activation1', 'alternative']\n",
    "activation_2 = results_reduced.loc['activation2', 'alternative']\n",
    "lr = results_reduced.loc['learning_rate', 'alternative']\n",
    "\n",
    "# Create a sequential neural network model\n",
    "nn_alternative = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_alternative.add(Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_1))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_alternative.add(Dense(units=hidden_nodes_layer2, activation=activation_2))\n",
    "\n",
    "# Add the output layer\n",
    "nn_alternative.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model \n",
    "# Set the parameters as mean_squared_error, adam, and accuracy.\n",
    "nn_alternative.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "deep_net_alternative_model = nn_alternative.fit(X_train_reduced_alternative_scaled, y_train_alternative, epochs=100, verbose=0)\n",
    "\n",
    "model_loss, model_accuracy = nn_alternative.evaluate(X_test_reduced_alternative_scaled, y_test_alternative, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9da7bb63-6561-4c1a-9c16-d82e4dddfb63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conservative Model\n",
      "Loss: 0.7131738066673279, Accuracy: 0.5415019989013672\n",
      "\n",
      "Balanced Model\n",
      "Loss: 0.8443578481674194, Accuracy: 0.5375494360923767\n",
      "\n",
      "Growth Model\n",
      "Loss: 0.7939696311950684, Accuracy: 0.5378485918045044\n",
      "\n",
      "Aggressive Model\n",
      "Loss: 0.7352592349052429, Accuracy: 0.5019920468330383\n",
      "\n",
      "Alternative Model\n",
      "Loss: 0.7515614628791809, Accuracy: 0.5338645577430725\n"
     ]
    }
   ],
   "source": [
    "#Conservative Portfolio\n",
    "# deep_net_conservative_model = nn_conservative.fit(X_train_full_conservative_scaled, y_train_conservative, epochs=100)\n",
    "\n",
    "# Evaluate Conservative Model using testing data\n",
    "model_loss, model_accuracy = nn_conservative.evaluate(X_test_reduced_conservative_scaled, y_test_conservative, verbose=0)\n",
    "\n",
    "print(f\"\\nConservative Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "#Balanced Portfolio\n",
    "# deep_net_balanced_model = nn_balanced.fit(X_train_full_balanced_scaled, y_train_balanced, epochs=100)\n",
    "\n",
    "#Evaluate Balanced Model using testing data\n",
    "model_loss, model_accuracy = nn_balanced.evaluate(X_test_reduced_balanced_scaled, y_test_balanced, verbose=0)\n",
    "\n",
    "print(f\"\\nBalanced Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#Growth Portfolio\n",
    "# deep_net_growth_model = nn_growth.fit(X_train_full_growth_scaled, y_train_growth, epochs=100)\n",
    "\n",
    "#Evaluate Growth Model using testing data\n",
    "model_loss, model_accuracy = nn_growth.evaluate(X_test_reduced_growth_scaled, y_test_growth, verbose=0)\n",
    "\n",
    "print(f\"\\nGrowth Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "#Aggressive Portfolio\n",
    "# deep_net_aggressive_model = nn_aggressive.fit(X_train_full_aggressive_scaled, y_train_aggressive, epochs=100)\n",
    "\n",
    "#Evaluate Aggressive Model using testing data\n",
    "model_loss, model_accuracy = nn_aggressive.evaluate(X_test_reduced_aggressive_scaled, y_test_aggressive, verbose=0)\n",
    "\n",
    "print(f\"\\nAggressive Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#Alternative Portfolio\n",
    "# deep_net_alternative_model = nn_alternative.fit(X_train_full_alternative_scaled, y_train_alternative, epochs=100)\n",
    "\n",
    "#Evaluate Alternative Model using testing data\n",
    "model_loss, model_accuracy = nn_alternative.evaluate(X_test_reduced_alternative_scaled, y_test_alternative, verbose=0)\n",
    "\n",
    "print(f\"\\nAlternative Model\\nLoss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b23316-0595-479b-8c01-e2e54178325a",
   "metadata": {},
   "source": [
    "### Make predictions using trained models. Save both class predicitions and prediction probabiities for evaluation score calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfe4a6bb-35f9-4fa8-a4cc-d2049c4b2b14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 873us/step\n",
      "8/8 [==============================] - 0s 979us/step\n",
      "8/8 [==============================] - 0s 953us/step\n",
      "8/8 [==============================] - 0s 934us/step\n",
      "8/8 [==============================] - 0s 853us/step\n"
     ]
    }
   ],
   "source": [
    "reduced_alternative_proba = nn_alternative.predict(X_test_reduced_alternative_scaled)\n",
    "reduced_aggressive_proba = nn_aggressive.predict(X_test_reduced_aggressive_scaled)\n",
    "reduced_growth_proba = nn_growth.predict(X_test_reduced_growth_scaled)\n",
    "reduced_balanced_proba = nn_balanced.predict(X_test_reduced_balanced_scaled)\n",
    "reduced_conservative_proba = nn_conservative.predict(X_test_reduced_conservative_scaled)\n",
    "\n",
    "reduced_alternative_preds = tf.cast(reduced_alternative_proba >= 0.5, tf.int32)\n",
    "reduced_aggressive_preds = tf.cast(reduced_aggressive_proba >= 0.5, tf.int32)\n",
    "reduced_growth_preds = tf.cast(reduced_growth_proba >= 0.5, tf.int32)\n",
    "reduced_balanced_preds = tf.cast(reduced_balanced_proba >= 0.5, tf.int32)\n",
    "reduced_conservative_preds = tf.cast(reduced_conservative_proba >= 0.5, tf.int32)\n",
    "\n",
    "reduced_preds = {'alternative': [reduced_alternative_proba, reduced_alternative_preds],\n",
    "              'aggressive': [reduced_aggressive_proba, reduced_aggressive_preds],\n",
    "              'growth': [reduced_growth_proba, reduced_growth_preds],\n",
    "              'balanced': [reduced_balanced_proba, reduced_balanced_preds],\n",
    "              'conservative': [reduced_conservative_proba, reduced_conservative_preds]\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa410e1-7f86-46a8-952a-9fe812e2a593",
   "metadata": {},
   "source": [
    "### compile tables of all evalutaion results for both full and reduced data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e99f2dd-3c63-471c-8268-841f838dbb0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>reduced</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">conservative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.534813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.442308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">balanced</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.474548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">growth</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.511686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.699482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">aggressive</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.536995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">alternative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.524174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.677686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             reduced\n",
       "type                                \n",
       "conservative roc_auc_score  0.534813\n",
       "             f1_score       0.442308\n",
       "balanced     roc_auc_score  0.474548\n",
       "             f1_score       0.697674\n",
       "growth       roc_auc_score  0.511686\n",
       "             f1_score       0.699482\n",
       "aggressive   roc_auc_score  0.536995\n",
       "             f1_score       0.285714\n",
       "alternative  roc_auc_score  0.524174\n",
       "             f1_score       0.677686"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_results = pd.DataFrame()\n",
    "for p in portfolios:\n",
    "    y_test = datafiles_reduced[p][3]\n",
    "    proba = reduced_preds[p][0]\n",
    "    preds = reduced_preds[p][1]\n",
    "    roc = roc_auc_score(y_test,proba)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    df = pd.DataFrame()\n",
    "    df.loc['roc_auc_score','reduced'] = roc\n",
    "    df.loc['f1_score', 'reduced'] = f1\n",
    "    df['type'] = p\n",
    "    reduced_results = pd.concat([reduced_results, df], axis=0)\n",
    "\n",
    "\n",
    "reduced_results.set_index('type', append=True, inplace=True)\n",
    "\n",
    "reduced_results = reduced_results.reorder_levels(['type',0])\n",
    "\n",
    "reduced_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b480072-18d1-4364-b757-025e129d721d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>full</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">conservative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.536750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">balanced</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.484446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.699229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">growth</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.481034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.572414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">aggressive</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.696104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">alternative</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <td>0.552303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.528736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                full\n",
       "type                                \n",
       "conservative roc_auc_score  0.536750\n",
       "             f1_score       0.545455\n",
       "balanced     roc_auc_score  0.484446\n",
       "             f1_score       0.699229\n",
       "growth       roc_auc_score  0.481034\n",
       "             f1_score       0.572414\n",
       "aggressive   roc_auc_score  0.500000\n",
       "             f1_score       0.696104\n",
       "alternative  roc_auc_score  0.552303\n",
       "             f1_score       0.528736"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results = pd.DataFrame()\n",
    "for p in portfolios:\n",
    "    y_test = datafiles_full[p][3]\n",
    "    proba = full_preds[p][0]\n",
    "    preds = full_preds[p][1]\n",
    "    roc = roc_auc_score(y_test,proba)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    df = pd.DataFrame()\n",
    "    df.loc['roc_auc_score','full'] = roc\n",
    "    df.loc['f1_score', 'full'] = f1\n",
    "    df['type'] = p\n",
    "    full_results = pd.concat([full_results, df], axis=0)\n",
    "\n",
    "\n",
    "full_results.set_index('type', append=True, inplace=True)\n",
    "\n",
    "full_results = full_results.reorder_levels(['type',0])\n",
    "full_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3eeb3-a8ab-4254-a484-bf758d5c3134",
   "metadata": {},
   "source": [
    "### combine full and reduced data evalutionas into one table for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01780ac9-66c6-4318-b9c5-ec2d517d0196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_results = pd.concat([full_results, reduced_results], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f15ac57-7167-4f33-a62e-477d72aee987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9f2ff_row0_col0, #T_9f2ff_row1_col0, #T_9f2ff_row2_col0, #T_9f2ff_row3_col0, #T_9f2ff_row4_col1, #T_9f2ff_row5_col1, #T_9f2ff_row6_col1, #T_9f2ff_row7_col0, #T_9f2ff_row8_col0, #T_9f2ff_row9_col1 {\n",
       "  background-color: lightblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9f2ff\">\n",
       "  <caption>Metrics Comparison for All Models</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9f2ff_level0_col0\" class=\"col_heading level0 col0\" >full</th>\n",
       "      <th id=\"T_9f2ff_level0_col1\" class=\"col_heading level0 col1\" >reduced</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >type</th>\n",
       "      <th class=\"index_name level1\" >&nbsp;</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9f2ff_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">conservative</th>\n",
       "      <th id=\"T_9f2ff_level1_row0\" class=\"row_heading level1 row0\" >roc_auc_score</th>\n",
       "      <td id=\"T_9f2ff_row0_col0\" class=\"data row0 col0\" >0.536750</td>\n",
       "      <td id=\"T_9f2ff_row0_col1\" class=\"data row0 col1\" >0.534813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f2ff_level1_row1\" class=\"row_heading level1 row1\" >f1_score</th>\n",
       "      <td id=\"T_9f2ff_row1_col0\" class=\"data row1 col0\" >0.545455</td>\n",
       "      <td id=\"T_9f2ff_row1_col1\" class=\"data row1 col1\" >0.442308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f2ff_level0_row2\" class=\"row_heading level0 row2\" rowspan=\"2\">balanced</th>\n",
       "      <th id=\"T_9f2ff_level1_row2\" class=\"row_heading level1 row2\" >roc_auc_score</th>\n",
       "      <td id=\"T_9f2ff_row2_col0\" class=\"data row2 col0\" >0.484446</td>\n",
       "      <td id=\"T_9f2ff_row2_col1\" class=\"data row2 col1\" >0.474548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f2ff_level1_row3\" class=\"row_heading level1 row3\" >f1_score</th>\n",
       "      <td id=\"T_9f2ff_row3_col0\" class=\"data row3 col0\" >0.699229</td>\n",
       "      <td id=\"T_9f2ff_row3_col1\" class=\"data row3 col1\" >0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f2ff_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"2\">growth</th>\n",
       "      <th id=\"T_9f2ff_level1_row4\" class=\"row_heading level1 row4\" >roc_auc_score</th>\n",
       "      <td id=\"T_9f2ff_row4_col0\" class=\"data row4 col0\" >0.481034</td>\n",
       "      <td id=\"T_9f2ff_row4_col1\" class=\"data row4 col1\" >0.511686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f2ff_level1_row5\" class=\"row_heading level1 row5\" >f1_score</th>\n",
       "      <td id=\"T_9f2ff_row5_col0\" class=\"data row5 col0\" >0.572414</td>\n",
       "      <td id=\"T_9f2ff_row5_col1\" class=\"data row5 col1\" >0.699482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f2ff_level0_row6\" class=\"row_heading level0 row6\" rowspan=\"2\">aggressive</th>\n",
       "      <th id=\"T_9f2ff_level1_row6\" class=\"row_heading level1 row6\" >roc_auc_score</th>\n",
       "      <td id=\"T_9f2ff_row6_col0\" class=\"data row6 col0\" >0.500000</td>\n",
       "      <td id=\"T_9f2ff_row6_col1\" class=\"data row6 col1\" >0.536995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f2ff_level1_row7\" class=\"row_heading level1 row7\" >f1_score</th>\n",
       "      <td id=\"T_9f2ff_row7_col0\" class=\"data row7 col0\" >0.696104</td>\n",
       "      <td id=\"T_9f2ff_row7_col1\" class=\"data row7 col1\" >0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f2ff_level0_row8\" class=\"row_heading level0 row8\" rowspan=\"2\">alternative</th>\n",
       "      <th id=\"T_9f2ff_level1_row8\" class=\"row_heading level1 row8\" >roc_auc_score</th>\n",
       "      <td id=\"T_9f2ff_row8_col0\" class=\"data row8 col0\" >0.552303</td>\n",
       "      <td id=\"T_9f2ff_row8_col1\" class=\"data row8 col1\" >0.524174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9f2ff_level1_row9\" class=\"row_heading level1 row9\" >f1_score</th>\n",
       "      <td id=\"T_9f2ff_row9_col0\" class=\"data row9 col0\" >0.528736</td>\n",
       "      <td id=\"T_9f2ff_row9_col1\" class=\"data row9 col1\" >0.677686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dacff670>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.style.highlight_max(color='lightblue', axis = 1).set_caption(\"Metrics Comparison for All Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75dcbf-2f0f-47aa-9dbb-42ca6a16c307",
   "metadata": {},
   "source": [
    "### save evalution results for 'best' model to a csv for use in comparing evalutaion results of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74316961-c73a-4b5c-9a7d-3b95f79994fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best = all_results[['reduced']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c943383-4b26-47f9-a2bf-17ec0e2c50cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96f65f23-2c1e-442a-b993-76ec66876a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best.to_csv(Path(\"./model_metrics/nn.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b89598-26e2-4739-bb31-e3651af20075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f20e5153-1cd5-4dbd-bdf8-e8e086fe2798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conservative</th>\n",
       "      <th>balanced</th>\n",
       "      <th>growth</th>\n",
       "      <th>aggressive</th>\n",
       "      <th>alternative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>units1</th>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>units2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation1</th>\n",
       "      <td>relu</td>\n",
       "      <td>tanh</td>\n",
       "      <td>tanh</td>\n",
       "      <td>tanh</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation2</th>\n",
       "      <td>tanh</td>\n",
       "      <td>tanh</td>\n",
       "      <td>tanh</td>\n",
       "      <td>relu</td>\n",
       "      <td>tanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              conservative balanced growth aggressive alternative\n",
       "units1                  26       32     36         34          30\n",
       "units2                   3        3      3          3           3\n",
       "activation1           relu     tanh   tanh       tanh        relu\n",
       "activation2           tanh     tanh   tanh       relu        tanh\n",
       "learning_rate         0.01     0.01  0.001       0.01        0.01"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e8186-d5bc-4c46-9c4d-b218673094e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
